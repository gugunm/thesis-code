{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real dataset\n",
    "datapath = './dataset/dataset-quran.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concept path buat di drive\n",
    "conceptpath = './assets/conceptInDrive.xlsx' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for real data ###\n",
    "TfResultPath = \"./assets/TfResultPath.bin.txt\"\n",
    "DfResultPath = \"./assets/DfResultPath.bin.txt\"\n",
    "TfIdfResultPath = \"./assets/TfIdfResultPath.bin.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leskOutputPath = \"./assets/realTrainLeskModel_1_100.bin.txt\"\n",
    "\n",
    "# leskOutputPath = \"./assets/realTrainLeskModel_100_200.bin.txt\"\n",
    "\n",
    "# leskOutputPath = \"./assets/realTrainLeskModel_200_300.bin.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leskOutputPath = \"./assets/realTrainLeskModel_124.bin.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordembedLeskPath = \"./assets/realTrainWordembedModel.bin.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Ke-1\n",
    "startAyat = 0\n",
    "endAyat = 100\n",
    "\n",
    "# Running Ke-2\n",
    "# startAyat = 100\n",
    "# endAyat = 200\n",
    "\n",
    "# Running Ke-3\n",
    "\n",
    "# Running Ke-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFileBin(path = ''):\n",
    "    file = open(path, 'rb')\n",
    "    object_file = pickle.load(file)\n",
    "    return object_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input   : -\n",
    "Output  : list of terms\n",
    "Problem : ambil terms wiki di  google sheet\n",
    "'''\n",
    "def getListTermsFromSheet(sheetname, datapath = datapath):\n",
    "    dfUWords = pd.read_excel(datapath, sheet_name=sheetname)\n",
    "    # Convert word false and true as str\n",
    "    booldict = {True: 'true', False: 'false'}\n",
    "    dfUWords = dfUWords.replace(booldict)\n",
    "    return dfUWords.values.ravel()\n",
    "\n",
    "def getTerms():\n",
    "    # ambil data terms dari drive\n",
    "    listTerms= getListTermsFromSheet('wiki-unique-words')\n",
    "    return listTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConcepts():\n",
    "    dfConcept = pd.read_excel(conceptpath)\n",
    "    return dfConcept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definisikan concepts\n",
    "dfConcept = getConcepts()\n",
    "# definisikan terms dengan --- function getTerms() ---\n",
    "listTerms = getTerms().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF dan IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Dilakukan di spyder, karena memory ga kuat kalo pake data concepts yang pake excell```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INI UNTUK TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(path):\n",
    "    tf = readFileBin(path)\n",
    "    return tf\n",
    "\n",
    "def get_df(path):\n",
    "    df = readFileBin(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*** ubah path ini kalo dipake buat data real\n",
    "tf = get_tf(TfResultPath)\n",
    "tf = tf.astype('uint8')\n",
    "#*** ubah path ini kalo dipake buat data real\n",
    "dfDocFreq = get_df(DfResultPath)\n",
    "dfDocFreq = dfDocFreq.astype('float16')\n",
    "# docs = tf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Desc    : IDF\n",
    "Input   : -\n",
    "Output  : matrix idf. Fungsi ini buat tf-idfnya lesk algorithm yag udah ditambah overlaps\n",
    "DONE Date: 21/10/2020\n",
    "'''\n",
    "# # INI YANG BARU DIUBAAAAAHAHHHHH\n",
    "# def tf_idf(dfTfWithOverlaps, dfDocFreq):\n",
    "#     # get terms\n",
    "#     terms = dfTfWithOverlaps.index\n",
    "#     # get docs\n",
    "#     docs  = dfTfWithOverlaps.columns\n",
    "#     # create dataframe for tfidf\n",
    "#     dfTfIdf = dfTfWithOverlaps.copy()\n",
    "    \n",
    "#     for i, doc in enumerate(docs):\n",
    "#         for j, term in enumerate(terms):\n",
    "#             # overwrite tfidf dataframe dengan hasil perhitungan tfidf\n",
    "#             dfTfIdf.loc[term, doc] = dfTfWithOverlaps.loc[term, doc]*dfDocFreq.loc[term, 'docfreq']\n",
    "   \n",
    "#     return dfTfIdf\n",
    "\n",
    "# INI YANG BARU DIUBAAAAAHAHHHHH\n",
    "\n",
    "# dictTermsWindowingConcepts = {\n",
    "#     \"name\": [1,2,3],\n",
    "#     \"allah\": [2, 4, 5],\n",
    "#     \"beneficent\": [1, 2, 3]\n",
    "# }\n",
    "\n",
    "def tf_idf(dictTermsWindowingConcepts):\n",
    "    listOfTerms = dfDocFreq.index\n",
    "    # Iterating over keys \n",
    "    for state in dictTermsWindowingConcepts: \n",
    "        if state in listOfTerms:\n",
    "            dictTermsWindowingConcepts[state] = np.array(dictTermsWindowingConcepts[state])*dfDocFreq.loc[state, 'docfreq']\n",
    "        else:\n",
    "            # kalo wordnya ga ada, defaultnya 1\n",
    "            dictTermsWindowingConcepts[state] = np.array(dictTermsWindowingConcepts[state])* math.log10(40147/1)\n",
    "    return dictTermsWindowingConcepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesk Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Struktur Function di Lesk Algorithm**\n",
    "```\n",
    "- func-leskAlgorithm\n",
    "    |\n",
    "    - func-weighting\n",
    "        |\n",
    "        - (inisiasi dataframe term-by-concept)\n",
    "        - func-windowing\n",
    "        - func-termByConceptMatrixWeighted\n",
    "            |\n",
    "            - func-tokenizeWordnetDefinition\n",
    "            - func-countOverlapDefinition\n",
    "            - func-countOverlapsConcept\n",
    "            - func-calculateTargetTermConceptVector\n",
    "            - func-insertTargetWordVectorToDf\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting terms by concepts\n",
    "\n",
    "```\n",
    "# Ada line yang harus dihapus untuk data yang real\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 1. ============'''\n",
    "'''\n",
    "Input   : insert vector target word ke matriks dataframe ayat\n",
    "Output  : matriks dataframe ayat\n",
    "Problem : -\n",
    "DONE Date: 21/10/2020\n",
    "''' \n",
    "def insertTargetWordVectorToDf(dfTermsConcepts, dictTargetWordVector):\n",
    "    # ambil target word sembari hapus key-nya\n",
    "    targetWord = dictTargetWordVector.pop('target_kata', None)\n",
    "    # dict dijadikan array - mempermudah looping\n",
    "    dictItems = dictTargetWordVector.items()\n",
    "    \n",
    "    # looping tiap items dict target word\n",
    "    for i, item in enumerate(dictItems):\n",
    "        # ambil pageName dari tuple item\n",
    "        pageName = item[0]\n",
    "        # if pageName in dfTermsConcepts.columns:\n",
    "        dfTermsConcepts.loc[targetWord, pageName] = dictTargetWordVector[pageName]\n",
    "        # else:\n",
    "            # dfTermsConcepts.loc[targetWord, pageName] = 0.0\n",
    "        # print('INSERTED : ', i, ' / ', dfTermsConcepts.loc[targetWord, pageName])\n",
    "    \n",
    "    return dfTermsConcepts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''============ 2. ============'''\n",
    "'''\n",
    "Input   : hitung concept vector untuk target word\n",
    "Output  : Vector of target terms by concepts\n",
    "Problem : -\n",
    "DONE Date: 21/10/2020\n",
    "''' \n",
    "# INI YANG BARU DIUBAAAAAHAHHHHH\n",
    "def calculateTargetTermConceptVector(dictNormalizedWindowingConcepts, targetWord):\n",
    "    # milai concept windows\n",
    "    cw = len(dictNormalizedWindowingConcepts)\n",
    "    # inisiasi untuk target vector\n",
    "    vectorTargetWord = []\n",
    "\n",
    "    for i, state in enumerate(dictNormalizedWindowingConcepts):\n",
    "        if i == 0:\n",
    "            vectorTargetWord = dictNormalizedWindowingConcepts[state]\n",
    "        else:\n",
    "            vectorTargetWord = np.add(vectorTargetWord, dictNormalizedWindowingConcepts[state])\n",
    "    \n",
    "#     print(targetWord, \"\\n\")\n",
    "#     display(vectorTargetWord)\n",
    "    \n",
    "    return vectorTargetWord\n",
    "\n",
    "\n",
    "\n",
    "'''============ 3. ============ \n",
    "@PERBAIKI, yang ditambah cuma target wordnya aja\n",
    "@DONE\n",
    "'''\n",
    "'''\n",
    "Input   : - windowingWords\n",
    "Output  : Vector of terms by concepts\n",
    "Problem : - ngitungnya\n",
    "DONE Date: 21/10/2020\n",
    "''' \n",
    "# INI YANG BARU DIUBAAAAAHAHHHHH\n",
    "def countOverlapsConcept(windowingWords, countOverlapsContext):\n",
    "    listOfPages = tf.columns\n",
    "    \n",
    "    listOfTerms = tf.index\n",
    "    \n",
    "    dictTermsWindowingConcepts = {}\n",
    "    \n",
    "#     dfTermsWindowingConcepts = pd.DataFrame(0, index=windowingWords, columns=listOfPages)\n",
    "\n",
    "#     print(\"countOverlapsContext : \", countOverlapsContext)\n",
    "    for word in windowingWords:        \n",
    "        windowWordVector = []\n",
    "        for page in listOfPages:\n",
    "            # Cell diisi jumlah term frequency + jumlah overlaps\n",
    "            if word in listOfTerms:\n",
    "                windowWordVector.append(tf.loc[word, page] + next(item for item in countOverlapsContext if item[\"word\"] == word)['overlap'])\n",
    "            else:\n",
    "                windowWordVector.append(0 + next(item for item in countOverlapsContext if item[\"word\"] == word)['overlap'])\n",
    "                #             dfTermsWindowingConcepts.loc[word, page] = tf.loc[word, page] + next(item for item in countOverlapsContext if item[\"word\"] == word)['overlap']\n",
    "        dictTermsWindowingConcepts[word] = windowWordVector\n",
    "    \n",
    "# #     data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\n",
    "#     dfTermsWindowingConcepts = pd.DataFrame.from_dict(dictTermsWindowingConcepts, orient='index')\n",
    "    # Normalize Matriks Term Frequency using IDF\n",
    "#     dfNormalizedWindowingConcepts = tf_idf(dfTermsWindowingConcepts, dfDocFreq)\n",
    "    dictNormalizedWindowingConcepts = tf_idf(dictTermsWindowingConcepts)\n",
    "    \n",
    "#     #******* PRINT\n",
    "#     display(dfNormalizedWindowingConcepts)\n",
    "\n",
    "    return dictNormalizedWindowingConcepts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''============ 4. ============ \n",
    "@Perbaiki Perhitungan Overlaps Pada WordNet-nya (liat paper rujukan)\n",
    "@DONE'''\n",
    "'''\n",
    "Input   : - hasil ravel of list of tokenization definition from wordnet\n",
    "Output  : Count of overlap\n",
    "Problem : - cara ngitungnya gimana\n",
    "''' \n",
    "def countOverlapDefinition(windowingWords, windowingWordsDef):\n",
    "    windowOverlaps = []\n",
    "    for word in windowingWords:\n",
    "        # nntinya buat dihapus bergantian, sesuai word saat ini\n",
    "        listWindowingWords = windowingWords.tolist().copy()\n",
    "        # ambil element windowingDef berdasarkan kata saat ini\n",
    "        wordDef = next(item for item in windowingWordsDef if item[\"word\"] == word)\n",
    "        # hitung overlaps concept window dengan definisi kata-nya\n",
    "        countOverlap = 0\n",
    "        listWindowingWords.remove(word)\n",
    "        for el in listWindowingWords:\n",
    "            # cari string word di definition, ambil panjang arraynya\n",
    "            countSearchRegex = len(re.findall(\"{}\".format(el), wordDef['def']))\n",
    "            countOverlap += countSearchRegex\n",
    "        windowOverlaps.append({\n",
    "            \"word\": word,\n",
    "            \"overlap\": countOverlap\n",
    "        })\n",
    "    return windowOverlaps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''============ 5. ============ \n",
    "@PERBAIKI, Kita Harus tau mana definisi untuk tiap kata di windowingnya - simpen di dict\n",
    "@DONE\n",
    "'''\n",
    "'''\n",
    "Input   : - word\n",
    "Output  : hasil ravel of list of tokenization definition from wordnet\n",
    "Problem : - remove punct\n",
    "          - return ravel dari list of definition of word in tokenization\n",
    "'''   \n",
    "def tokenizeWordnetDefinition(word):\n",
    "    listOfDefinition = []\n",
    "    # ngambil list definition dari suatu word\n",
    "    definitions = wn.synsets(word)\n",
    "    for d in definitions:\n",
    "        # clean def dari non-alphabet\n",
    "        strDef = re.sub('[^A-Za-z]+',' ', d.definition())\n",
    "        listOfDefinition.append(strDef)\n",
    "    # join semua definisi ke satu str\n",
    "    ravelListOfDefinition = \" \".join(listOfDefinition)\n",
    "    return ravelListOfDefinition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windowing and Main Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 6. ============'''\n",
    "'''\n",
    "Input   : - matrix zero dengan index terms dan kolom concepts\n",
    "          - windowing words\n",
    "          - target word\n",
    "Output  : matrix terms-by-concepts yang sudah ada weight-nya dari target word pada suatu ayat\n",
    "Problem : - weighting dengan wordnet\n",
    "          - hitung overlapping dengan lesk algorithm\n",
    "          - normalize dengan tf-idf\n",
    "'''     \n",
    "def termByConceptMatrixWeighted(windowingWords, targetWord):\n",
    "    # Count Overlaps Context\n",
    "    windowingWordsDef = []\n",
    "    for w in windowingWords:\n",
    "        # tokenizedDef harusnya bentuknya dict, nyimpe wordnya apa, dan token definisinya\n",
    "        tokenizedDef = tokenizeWordnetDefinition(w)\n",
    "        wordDef = {\n",
    "            \"word\": w,\n",
    "            \"def\": tokenizedDef\n",
    "        }\n",
    "        windowingWordsDef.append(wordDef)\n",
    "\n",
    "    # print(\"## WORD DEF \", windowingWordsDef)\n",
    "        \n",
    "    # Count Overlaps WordNet\n",
    "    # windowingWordsDef = [{'word': 'name', 'def': 'merciful beneficent beneficent a language unit by which a person or thing is known a person s reputation family based on male descent a well known or notable person by the sanction or authority of a defamatory or abusive word or phrase assign a specified usually proper proper name to give the name or identifying characteristics of refer to by name or some other identifying characteristic property charge with a function charge to be create and charge with a task or function mention and identify by name make reference to identify as in botany or biology for example give or make a list of name individually give the names of determine or distinguish the nature of a problem or an illness through a diagnostic analysis'}, {'word': 'allah', 'def': 'Muslim name for the one and only God'}, {'word': 'beneficent', 'def': 'doing or producing good generous in assistance to the poor'}, {'word': 'merciful', 'def': 'showing or giving mercy  used conventionally of royalty and high nobility gracious allah'}]\n",
    "    # windowingWords = ['name', 'allah', 'beneficent', 'merciful']\n",
    "    print('       - Count Overlaps...')\n",
    "    countOverlapsContext = countOverlapDefinition(windowingWords, windowingWordsDef)\n",
    "    # print(countOverlapsContext)\n",
    "        \n",
    "    print('       - Normalized Concept...')\n",
    "    # Count Overlaps Concept\n",
    "    dictNormalizedWindowingConcepts = countOverlapsConcept(windowingWords, countOverlapsContext)\n",
    "    \n",
    "#     print(dictNormalizedWindowingConcepts)\n",
    "       \n",
    "    print('       - Target Word Vector...')\n",
    "    # hitung vector term concept untuk target word\n",
    "    # return isi vector buat yang target word aja dalam bentuk dictionary\n",
    "    targetWordVector = calculateTargetTermConceptVector(dictNormalizedWindowingConcepts, targetWord)\n",
    "    \n",
    "    #******* PRINT\n",
    "#     print(\"TARGET WORD VECTOR : \", targetWordVector)\n",
    "\n",
    "        \n",
    "#     print('       - Insert Target Word Vector...')\n",
    "#     # function buat masukin vector target word ke dataframe terms concept ayat\n",
    "#     dfTermsConcepts = insertTargetWordVectorToDf(dfTermsConcepts, dictTargetWordVector)\n",
    "#     dfTermsConcepts\n",
    "    \n",
    "    return targetWordVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 7. ============'''\n",
    "'''\n",
    "Input   : jumlah windowing, ayat dan target word (indexnya)\n",
    "Output  : return words berdasarkan windowsnya\n",
    "Problem : - untuk data yang kurang dari jumlah window yang saat itu digunakan ? return semuanya\n",
    "          - cek dengan print dokumen dummy\n",
    "          - gimana kalo posisi target ada di (awal, tengah, ujung)\n",
    "'''\n",
    "def windowing(idxTarget, tokenAyat, n_window):\n",
    "    # 0 kalau ada minus\n",
    "    left = 0 if((idxTarget - n_window) < 0) else (idxTarget - n_window)\n",
    "    # len target kalau lebih dari length nya\n",
    "    right = (len(tokenAyat) - 1) if((idxTarget + n_window) > (len(tokenAyat) - 1)) else (idxTarget + n_window)\n",
    "    \n",
    "    # ambil kata-kata di kiri\n",
    "    leftWords = tokenAyat[left : idxTarget]\n",
    "    # ambil kata-kata dikanan\n",
    "    rightWords = tokenAyat[idxTarget+1 : right + 1]\n",
    "\n",
    "    # gabungkan jadi satu array\n",
    "    windowingWords = [tokenAyat[idxTarget]] + leftWords + rightWords\n",
    "    \n",
    "    # ========= PERUBAHAN PENTING NIH ===========\n",
    "    # delete word yang duplikat ketika berada dalam satu window\n",
    "    # kasusnya ayat ke-5 word \"thee\" \n",
    "    windowingWordsClean = np.unique(np.array(windowingWords))\n",
    "    \n",
    "    #print('{} - {} - target : {} '.format(leftWords, rightWords, tokenAyat[idxTarget]))\n",
    "    return windowingWordsClean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Child of Lesk Algorithm\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# Ada line yang harus dihapus untuk data yang real\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 8. ============'''\n",
    "'''\n",
    "Input   : token ayat dan jumlah windowing\n",
    "Output  : matrix terms-by-concepts dari suatu ayat\n",
    "Problem : - jumlah overlaps menggunakan wordNet \n",
    "          - jumlah kata di page, sesuai dengan jumlah konsepnya\n",
    "          - jumlah setiap term muncul di beberapa dokumen wikipedia (DF)\n",
    "'''\n",
    "# INI BARU DIUBAAAAAAAAAAAAAHHHH\n",
    "def weighting(tokenAyat, n_window):    \n",
    "    '''Bikin list page yang ada di dummy, delete line ini kalo buat real'''\n",
    "#     pageDummyList = []\n",
    "#     for pageName in dfConcept.name:\n",
    "#     if re.split(\"\\_\", pageName)[0] in listTerms:\n",
    "#         pageDummyList.append(pageName)\n",
    "\n",
    "    print('- Creating DataFrame Terms Concept...')\n",
    "    # # inisialisasi matrix kosongnya dulu untuk matriks terms-by-concept, untuk yang real\n",
    "    dfTermsConcepts = pd.DataFrame(0, index=list(range(len(dfConcept.name))) , columns=listTerms)\n",
    "#     dfTermsConcepts = pd.DataFrame(0, index=listTerms, columns=dfConcept.name)\n",
    "    dictTermsConcepts = {}\n",
    "\n",
    "    '''pake column yang dummy, delete line ini kalo buat real'''\n",
    "#     dfTermsConcepts = pd.DataFrame(0, index=listTerms, columns=pageDummyList)\n",
    "\n",
    "\n",
    "    print('- Windowing & Weighting...')\n",
    "    # looping for every word as target words\n",
    "    for idxTarget, targetWord in enumerate(tokenAyat):\n",
    "        print('  # Terget Word {}/{}'.format(idxTarget, len(tokenAyat)-1))\n",
    "        print('    Target Word : {}'.format(targetWord))\n",
    "        # --- function windowing() ---\n",
    "        print('    - Windowing...')\n",
    "        windowingWords = windowing(idxTarget, tokenAyat, n_window)\n",
    "        print('      Windowing Words : {}'.format(windowingWords))\n",
    "        # --- function termByConceptMatrixWeighted() ---\n",
    "        print('    - Weighting...')\n",
    "        # looping recursive buat ngisi nilai si dfTermsConcepts-nya\n",
    "        targetWordVector = termByConceptMatrixWeighted(windowingWords, targetWord)\n",
    "\n",
    "        dictTermsConcepts[targetWord] = targetWordVector\n",
    "        # #*** Nyoba 1 target word\n",
    "        #return dfTermsConcepts\n",
    "\n",
    "#     print(\"dictTermsConcepts : \", dictTermsConcepts)\n",
    "    \n",
    "    # ===== CATATAAAAAN ====\n",
    "    # replace column di dictTermsConcepts yang ada di token ayat\n",
    "    for term in dictTermsConcepts:\n",
    "        # dfTermsConcepts.iloc[listTerms.index(term)] = dictTermsConcepts[term]\n",
    "        dfTermsConcepts[term] = dictTermsConcepts[term]\n",
    "    \n",
    "    # Rubah dtypes biar ga terlalu gede sizenya\n",
    "#     dfTermsConcepts = dfTermsConcepts.astype('uint8')\n",
    "    dfTermsConcepts = dfTermsConcepts.astype('float16')\n",
    "    \n",
    "#     display(dfTermsConcepts)\n",
    "      \n",
    "    return dfTermsConcepts \n",
    "\n",
    "    # Lakukan proses weighting disetiap pages untuk setiap termsnya\n",
    "    # weight untuk target word (rumusnya ada di dokumen / catetan)\n",
    "    # setiap term akan memiliki weight dalam vector (concept vector) dengan panjang |wiki pages|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Lesk to .bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 10. ============'''\n",
    "'''\n",
    "Input   : term by concept matrices\n",
    "Output  : saved model in .bin.txt\n",
    "Problem : -\n",
    "DONE Date: 22/10/2020\n",
    "''' \n",
    "def saveTermsByConceptMatrices(idx, listWeightedAyat, leskOutputPath = './assets/leskOutput/ayat'):\n",
    "    with codecs.open(\"{}_{}\".format(leskOutputPath, idx), 'wb') as outfile:\n",
    "        pickle.dump(listWeightedAyat, outfile) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Lesk Algorithm\n",
    "\n",
    "```\n",
    "# Ada line yang harus dihapus untuk data yang real\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 9. ============'''\n",
    "'''\n",
    "Input   : file dataset\n",
    "Output  : matrices of terms-by-concept sebanyak documents\n",
    "Problem : - looping tiap ayat (doc)\n",
    "          - untuk setiap ayatnya, lakukan weighting oleh def yg lain\n",
    "'''\n",
    "def leskAlgorithm(n_window = 2):\n",
    "    # declare list buat nampung ayat yang udah di weighted\n",
    "    listWeightedAyat = []\n",
    "    \n",
    "    # AYAT YANG INGIN DIGUNAKAN\n",
    "    # ambil data dari drive\n",
    "    ayatInString = pd.read_excel(datapath, sheet_name='proceed-data').Terjemahan.values[startAyat : endAyat]\n",
    "    labelsAllAyat = pd.read_excel(datapath, sheet_name='proceed-data').iloc[:,4:20].values[startAyat : endAyat]\n",
    "    \n",
    "    \n",
    "    # Looping datanya\n",
    "    for idx, ayat in enumerate(ayatInString):\n",
    "        # create dictionary for every ayat\n",
    "        dictPerAyat = dict()\n",
    "\n",
    "        # insert label ayat to dict\n",
    "        dictPerAyat[\"labelsPerAyat\"] = np.uint8(labelsAllAyat[idx]) # labelsAllAyat[idx]\n",
    "\n",
    "        print('==== AYAT - {}/{} ===='.format(idx, len(ayatInString)-1))\n",
    "        # ubah string ke bentuk array\n",
    "        tokenAyat = ast.literal_eval(ayat)\n",
    "\n",
    "        # --- weighting pake function weighting() ---\n",
    "        print('# Lesk Algorithm...')\n",
    "        weightedAyat = weighting(tokenAyat, n_window)\n",
    "\n",
    "        # insert weighted ayat ke dictionary per ayat\n",
    "        # dibalik column dan indexnya\n",
    "        dictPerAyat[\"weightedAyat\"] = weightedAyat\n",
    "\n",
    "        # append weighted ayat ke list\n",
    "        # listWeightedAyat.append(dictPerAyat)\n",
    "        \n",
    "        \n",
    "        saveTermsByConceptMatrices(idx, dictPerAyat, leskOutputPath = './assets/leskOutput/ayat')\n",
    "        \n",
    "\n",
    "        #*** Nyoba 1 Ayat\n",
    "#         print('- Weighted Ayat with Lesk...')\n",
    "#         with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#             display(weightedAyat)\n",
    "#         return weightedAyat\n",
    "  \n",
    "    return 0 # listWeightedAyat\n",
    "\n",
    "\n",
    "\n",
    "#     idx = 24\n",
    "\n",
    "#     ayat = ayatInString[idx]\n",
    "#     # create dictionary for every ayat\n",
    "#     dictPerAyat = dict()\n",
    "\n",
    "#     # insert label ayat to dict\n",
    "#     dictPerAyat[\"labelsPerAyat\"] = labelsAllAyat[idx]\n",
    "    \n",
    "#     print(np.uint8(labelsAllAyat[idx]))\n",
    "#     print(labelsAllAyat[idx])\n",
    "\n",
    "#     print('==== AYAT - {}/{} ===='.format(idx, len(ayatInString)-1))\n",
    "#     # ubah string ke bentuk array\n",
    "#     tokenAyat = ast.literal_eval(ayat)\n",
    "\n",
    "#     # --- weighting pake function weighting() ---\n",
    "#     print('# Lesk Algorithm...')\n",
    "#     weightedAyat = weighting(tokenAyat, n_window)\n",
    "\n",
    "#     # insert weighted ayat ke dictionary per ayat\n",
    "#     # dibalik column dan indexnya\n",
    "#     dictPerAyat[\"weightedAyat\"] = weightedAyat\n",
    "\n",
    "#     # append weighted ayat ke list\n",
    "#     listWeightedAyat.append(dictPerAyat)\n",
    "  \n",
    "#     print(listWeightedAyat)\n",
    "#     listWeightedAyat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Lesk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== AYAT - 0/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/3\n",
      "    Target Word : name\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'beneficent' 'name']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/3\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'beneficent' 'merciful' 'name']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/3\n",
      "    Target Word : beneficent\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'beneficent' 'merciful' 'name']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/3\n",
      "    Target Word : merciful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'beneficent' 'merciful']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 1/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/4\n",
      "    Target Word : praise\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'due' 'praise']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/4\n",
      "    Target Word : due\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'due' 'lord' 'praise']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/4\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'due' 'lord' 'praise' 'world']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/4\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'due' 'lord' 'world']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/4\n",
      "    Target Word : world\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'lord' 'world']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 2/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/1\n",
      "    Target Word : beneficent\n",
      "    - Windowing...\n",
      "      Windowing Words : ['beneficent' 'merciful']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/1\n",
      "    Target Word : merciful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['beneficent' 'merciful']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 3/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/2\n",
      "    Target Word : master\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'judgment' 'master']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/2\n",
      "    Target Word : day\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'judgment' 'master']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/2\n",
      "    Target Word : judgment\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'judgment' 'master']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 4/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/4\n",
      "    Target Word : thee\n",
      "    - Windowing...\n",
      "      Windowing Words : ['serve' 'thee']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/4\n",
      "    Target Word : serve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['beseech' 'serve' 'thee']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/4\n",
      "    Target Word : thee\n",
      "    - Windowing...\n",
      "      Windowing Words : ['beseech' 'help' 'serve' 'thee']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/4\n",
      "    Target Word : beseech\n",
      "    - Windowing...\n",
      "      Windowing Words : ['beseech' 'help' 'serve' 'thee']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/4\n",
      "    Target Word : help\n",
      "    - Windowing...\n",
      "      Windowing Words : ['beseech' 'help' 'thee']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 5/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/3\n",
      "    Target Word : keep\n",
      "    - Windowing...\n",
      "      Windowing Words : ['keep' 'right' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/3\n",
      "    Target Word : u\n",
      "    - Windowing...\n",
      "      Windowing Words : ['keep' 'path' 'right' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/3\n",
      "    Target Word : right\n",
      "    - Windowing...\n",
      "      Windowing Words : ['keep' 'path' 'right' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/3\n",
      "    Target Word : path\n",
      "    - Windowing...\n",
      "      Windowing Words : ['path' 'right' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 6/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/12\n",
      "    Target Word : path\n",
      "    - Windowing...\n",
      "      Windowing Words : ['path' 'thou' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/12\n",
      "    Target Word : upon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hast' 'path' 'thou' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/12\n",
      "    Target Word : thou\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'hast' 'path' 'thou' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/12\n",
      "    Target Word : hast\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'favor' 'hast' 'thou' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/12\n",
      "    Target Word : bestowed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'favor' 'hast' 'path' 'thou']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/12\n",
      "    Target Word : favor\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'favor' 'hast' 'path' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/12\n",
      "    Target Word : path\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'favor' 'path' 'thy' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/12\n",
      "    Target Word : upon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['favor' 'path' 'thy' 'upon' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/12\n",
      "    Target Word : thy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['brought' 'path' 'thy' 'upon' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/12\n",
      "    Target Word : wrath\n",
      "    - Windowing...\n",
      "      Windowing Words : ['brought' 'go' 'thy' 'upon' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 10/12\n",
      "    Target Word : brought\n",
      "    - Windowing...\n",
      "      Windowing Words : ['astray' 'brought' 'go' 'thy' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/12\n",
      "    Target Word : go\n",
      "    - Windowing...\n",
      "      Windowing Words : ['astray' 'brought' 'go' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/12\n",
      "    Target Word : astray\n",
      "    - Windowing...\n",
      "      Windowing Words : ['astray' 'brought' 'go']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 7/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/2\n",
      "    Target Word : alif\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alif' 'lam' 'mim']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/2\n",
      "    Target Word : lam\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alif' 'lam' 'mim']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/2\n",
      "    Target Word : mim\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alif' 'lam' 'mim']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 8/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/4\n",
      "    Target Word : book\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'doubt' 'guide']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/4\n",
      "    Target Word : doubt\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'doubt' 'guard' 'guide']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/4\n",
      "    Target Word : guide\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'doubt' 'evil' 'guard' 'guide']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/4\n",
      "    Target Word : guard\n",
      "    - Windowing...\n",
      "      Windowing Words : ['doubt' 'evil' 'guard' 'guide']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/4\n",
      "    Target Word : evil\n",
      "    - Windowing...\n",
      "      Windowing Words : ['evil' 'guard' 'guide']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 9/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/5\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'keep' 'unseen']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/5\n",
      "    Target Word : unseen\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'keep' 'prayer' 'unseen']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/5\n",
      "    Target Word : keep\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'keep' 'prayer' 'spend' 'unseen']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/5\n",
      "    Target Word : prayer\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'keep' 'prayer' 'spend' 'unseen']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/5\n",
      "    Target Word : spend\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'keep' 'prayer' 'spend']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/5\n",
      "    Target Word : given\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'prayer' 'spend']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 10/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/4\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'revealed']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/4\n",
      "    Target Word : revealed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'revealed' 'sure']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/4\n",
      "    Target Word : revealed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'hereafter' 'revealed' 'sure']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/4\n",
      "    Target Word : sure\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hereafter' 'revealed' 'sure']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/4\n",
      "    Target Word : hereafter\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hereafter' 'revealed' 'sure']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 11/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/4\n",
      "    Target Word : right\n",
      "    - Windowing...\n",
      "      Windowing Words : ['course' 'lord' 'right']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/4\n",
      "    Target Word : course\n",
      "    - Windowing...\n",
      "      Windowing Words : ['course' 'lord' 'right' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/4\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['course' 'lord' 'right' 'shall' 'successful']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/4\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['course' 'lord' 'shall' 'successful']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/4\n",
      "    Target Word : successful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'shall' 'successful']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 12/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alike' 'disbelieve' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : disbelieve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alike' 'disbelieve' 'surely' 'whether']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : alike\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alike' 'disbelieve' 'surely' 'warn' 'whether']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : whether\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alike' 'disbelieve' 'warn' 'whether']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : warn\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alike' 'believe' 'warn' 'whether']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : warn\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'warn' 'whether']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'warn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 13/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/10\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'seal' 'set']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/10\n",
      "    Target Word : set\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'seal' 'set' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/10\n",
      "    Target Word : seal\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'heart' 'seal' 'set' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/10\n",
      "    Target Word : upon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['heart' 'seal' 'set' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/10\n",
      "    Target Word : heart\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hearing' 'heart' 'seal' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/10\n",
      "    Target Word : upon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['covering' 'hearing' 'heart' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/10\n",
      "    Target Word : hearing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['covering' 'eye' 'hearing' 'heart' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/10\n",
      "    Target Word : covering\n",
      "    - Windowing...\n",
      "      Windowing Words : ['covering' 'eye' 'great' 'hearing' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/10\n",
      "    Target Word : eye\n",
      "    - Windowing...\n",
      "      Windowing Words : ['covering' 'eye' 'great' 'hearing' 'punishment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/10\n",
      "    Target Word : great\n",
      "    - Windowing...\n",
      "      Windowing Words : ['covering' 'eye' 'great' 'punishment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/10\n",
      "    Target Word : punishment\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eye' 'great' 'punishment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 14/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : people\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'people' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'people' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'last' 'people' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'day' 'last' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : last\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'believer' 'day' 'last']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : day\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believer' 'day' 'last']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : believer\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believer' 'day' 'last']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 15/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/5\n",
      "    Target Word : desire\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'deceive' 'desire']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/5\n",
      "    Target Word : deceive\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'deceive' 'desire']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/5\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'deceive' 'desire']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/5\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'deceive' 'perceive']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/5\n",
      "    Target Word : deceive\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'deceive' 'perceive']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/5\n",
      "    Target Word : perceive\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'deceive' 'perceive']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 16/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/7\n",
      "    Target Word : disease\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'disease' 'heart']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/7\n",
      "    Target Word : heart\n",
      "    - Windowing...\n",
      "      Windowing Words : ['added' 'allah' 'disease' 'heart']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/7\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['added' 'allah' 'disease' 'heart']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/7\n",
      "    Target Word : added\n",
      "    - Windowing...\n",
      "      Windowing Words : ['added' 'allah' 'disease' 'heart' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/7\n",
      "    Target Word : disease\n",
      "    - Windowing...\n",
      "      Windowing Words : ['added' 'allah' 'disease' 'painful' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/7\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['added' 'chastisement' 'disease' 'painful' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/7\n",
      "    Target Word : painful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['chastisement' 'disease' 'painful' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/7\n",
      "    Target Word : chastisement\n",
      "    - Windowing...\n",
      "      Windowing Words : ['chastisement' 'painful' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 17/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['make' 'mischief' 'said']\n",
      "    - Weighting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : make\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'make' 'mischief' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : mischief\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'make' 'mischief' 'said' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : land\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'make' 'mischief' 'peace' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'maker' 'mischief' 'peace' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : peace\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'maker' 'peace' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : maker\n",
      "    - Windowing...\n",
      "      Windowing Words : ['maker' 'peace' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 18/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/3\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['maker' 'mischief' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/3\n",
      "    Target Word : mischief\n",
      "    - Windowing...\n",
      "      Windowing Words : ['maker' 'mischief' 'perceive' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/3\n",
      "    Target Word : maker\n",
      "    - Windowing...\n",
      "      Windowing Words : ['maker' 'mischief' 'perceive' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/3\n",
      "    Target Word : perceive\n",
      "    - Windowing...\n",
      "      Windowing Words : ['maker' 'mischief' 'perceive']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 19/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/11\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'people' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/11\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'people' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/11\n",
      "    Target Word : people\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'people' 'said' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/11\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'people' 'say' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/11\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'people' 'say' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/11\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'fool' 'say' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/11\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'fool' 'say' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/11\n",
      "    Target Word : fool\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'fool' 'shall' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/11\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'fool' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/11\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'fool' 'know' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/11\n",
      "    Target Word : fool\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'fool' 'know' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/11\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fool' 'know' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 20/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/8\n",
      "    Target Word : meet\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'meet' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/8\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'meet' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/8\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'believe' 'meet' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/8\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'believe' 'say' 'shaitan']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/8\n",
      "    Target Word : alone\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'believe' 'say' 'shaitan']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/8\n",
      "    Target Word : shaitan\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'believe' 'say' 'shaitan' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/8\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'mocking' 'say' 'shaitan' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/8\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['mocking' 'say' 'shaitan' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/8\n",
      "    Target Word : mocking\n",
      "    - Windowing...\n",
      "      Windowing Words : ['mocking' 'say' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 21/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/9\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'pay' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/9\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'back' 'pay' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/9\n",
      "    Target Word : pay\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'back' 'mockery' 'pay' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 3/9\n",
      "    Target Word : back\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'leaf' 'mockery' 'pay' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/9\n",
      "    Target Word : mockery\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'back' 'leaf' 'mockery' 'pay']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/9\n",
      "    Target Word : leaf\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'back' 'inordinacy' 'leaf' 'mockery']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/9\n",
      "    Target Word : alone\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'blindly' 'inordinacy' 'leaf' 'mockery']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/9\n",
      "    Target Word : inordinacy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'blindly' 'inordinacy' 'leaf' 'wandering']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/9\n",
      "    Target Word : blindly\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'blindly' 'inordinacy' 'wandering']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/9\n",
      "    Target Word : wandering\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blindly' 'inordinacy' 'wandering']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 22/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/10\n",
      "    Target Word : buy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['buy' 'error' 'right']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/10\n",
      "    Target Word : error\n",
      "    - Windowing...\n",
      "      Windowing Words : ['buy' 'direction' 'error' 'right']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/10\n",
      "    Target Word : right\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bargain' 'buy' 'direction' 'error' 'right']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/10\n",
      "    Target Word : direction\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bargain' 'direction' 'error' 'right' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/10\n",
      "    Target Word : bargain\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bargain' 'bring' 'direction' 'right' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/10\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bargain' 'bring' 'direction' 'gain' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/10\n",
      "    Target Word : bring\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bargain' 'bring' 'follower' 'gain' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/10\n",
      "    Target Word : gain\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bring' 'follower' 'gain' 'right' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/10\n",
      "    Target Word : follower\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bring' 'direction' 'follower' 'gain' 'right']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/10\n",
      "    Target Word : right\n",
      "    - Windowing...\n",
      "      Windowing Words : ['direction' 'follower' 'gain' 'right']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/10\n",
      "    Target Word : direction\n",
      "    - Windowing...\n",
      "      Windowing Words : ['direction' 'follower' 'right']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 23/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/15\n",
      "    Target Word : parable\n",
      "    - Windowing...\n",
      "      Windowing Words : ['like' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/15\n",
      "    Target Word : like\n",
      "    - Windowing...\n",
      "      Windowing Words : ['like' 'one' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/15\n",
      "    Target Word : parable\n",
      "    - Windowing...\n",
      "      Windowing Words : ['kindled' 'like' 'one' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/15\n",
      "    Target Word : one\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fire' 'kindled' 'like' 'one' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/15\n",
      "    Target Word : kindled\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fire' 'illumined' 'kindled' 'one' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/15\n",
      "    Target Word : fire\n",
      "    - Windowing...\n",
      "      Windowing Words : ['around' 'fire' 'illumined' 'kindled' 'one']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/15\n",
      "    Target Word : illumined\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'around' 'fire' 'illumined' 'kindled']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/15\n",
      "    Target Word : around\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'around' 'fire' 'illumined' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/15\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'around' 'away' 'illumined' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/15\n",
      "    Target Word : took\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'around' 'away' 'light' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/15\n",
      "    Target Word : away\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'away' 'left' 'light' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/15\n",
      "    Target Word : light\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'left' 'light' 'took' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/15\n",
      "    Target Word : left\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'darkness' 'left' 'light' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/15\n",
      "    Target Word : utter\n",
      "    - Windowing...\n",
      "      Windowing Words : ['darkness' 'left' 'light' 'see' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/15\n",
      "    Target Word : darkness\n",
      "    - Windowing...\n",
      "      Windowing Words : ['darkness' 'left' 'see' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/15\n",
      "    Target Word : see\n",
      "    - Windowing...\n",
      "      Windowing Words : ['darkness' 'see' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "==== AYAT - 24/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/4\n",
      "    Target Word : deaf\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blind' 'deaf' 'dumb']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/4\n",
      "    Target Word : dumb\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blind' 'deaf' 'dumb' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/4\n",
      "    Target Word : blind\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'blind' 'deaf' 'dumb' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/4\n",
      "    Target Word : turn\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'blind' 'dumb' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/4\n",
      "    Target Word : back\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'blind' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 25/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/17\n",
      "    Target Word : like\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abundant' 'like' 'rain']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/17\n",
      "    Target Word : abundant\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abundant' 'cloud' 'like' 'rain']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/17\n",
      "    Target Word : rain\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abundant' 'cloud' 'like' 'rain' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/17\n",
      "    Target Word : cloud\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abundant' 'cloud' 'darkness' 'rain' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/17\n",
      "    Target Word : utter\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cloud' 'darkness' 'rain' 'thunder' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/17\n",
      "    Target Word : darkness\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cloud' 'darkness' 'lightning' 'thunder' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/17\n",
      "    Target Word : thunder\n",
      "    - Windowing...\n",
      "      Windowing Words : ['darkness' 'lightning' 'put' 'thunder' 'utter']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/17\n",
      "    Target Word : lightning\n",
      "    - Windowing...\n",
      "      Windowing Words : ['darkness' 'finger' 'lightning' 'put' 'thunder']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/17\n",
      "    Target Word : put\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ear' 'finger' 'lightning' 'put' 'thunder']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/17\n",
      "    Target Word : finger\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ear' 'finger' 'lightning' 'put' 'thunder']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/17\n",
      "    Target Word : ear\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ear' 'finger' 'peal' 'put' 'thunder']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/17\n",
      "    Target Word : thunder\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ear' 'fear' 'finger' 'peal' 'thunder']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/17\n",
      "    Target Word : peal\n",
      "    - Windowing...\n",
      "      Windowing Words : ['death' 'ear' 'fear' 'peal' 'thunder']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/17\n",
      "    Target Word : fear\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'death' 'fear' 'peal' 'thunder']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/17\n",
      "    Target Word : death\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'death' 'encompasses' 'fear' 'peal']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/17\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'death' 'encompasses' 'fear' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/17\n",
      "    Target Word : encompasses\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'death' 'encompasses' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/17\n",
      "    Target Word : unbeliever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'encompasses' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 26/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/23\n",
      "    Target Word : lightning\n",
      "    - Windowing...\n",
      "      Windowing Words : ['almost' 'lightning' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/23\n",
      "    Target Word : almost\n",
      "    - Windowing...\n",
      "      Windowing Words : ['almost' 'away' 'lightning' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/23\n",
      "    Target Word : take\n",
      "    - Windowing...\n",
      "      Windowing Words : ['almost' 'away' 'lightning' 'sight' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/23\n",
      "    Target Word : away\n",
      "    - Windowing...\n",
      "      Windowing Words : ['almost' 'away' 'sight' 'take' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/23\n",
      "    Target Word : sight\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'shine' 'sight' 'take' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/23\n",
      "    Target Word : whenever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'shine' 'sight' 'walk' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/23\n",
      "    Target Word : shine\n",
      "    - Windowing...\n",
      "      Windowing Words : ['becomes' 'shine' 'sight' 'walk' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/23\n",
      "    Target Word : walk\n",
      "    - Windowing...\n",
      "      Windowing Words : ['becomes' 'dark' 'shine' 'walk' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/23\n",
      "    Target Word : becomes\n",
      "    - Windowing...\n",
      "      Windowing Words : ['becomes' 'dark' 'shine' 'stand' 'walk']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/23\n",
      "    Target Word : dark\n",
      "    - Windowing...\n",
      "      Windowing Words : ['becomes' 'dark' 'stand' 'still' 'walk']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/23\n",
      "    Target Word : stand\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'becomes' 'dark' 'stand' 'still']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 11/23\n",
      "    Target Word : still\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'dark' 'pleased' 'stand' 'still']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/23\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'pleased' 'stand' 'still' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/23\n",
      "    Target Word : pleased\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'certainly' 'pleased' 'still' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/23\n",
      "    Target Word : would\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'certainly' 'pleased' 'taken' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/23\n",
      "    Target Word : certainly\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'certainly' 'pleased' 'taken' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/23\n",
      "    Target Word : taken\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'certainly' 'hearing' 'taken' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/23\n",
      "    Target Word : away\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'certainly' 'hearing' 'sight' 'taken']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/23\n",
      "    Target Word : hearing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['away' 'hearing' 'sight' 'surely' 'taken']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 19/23\n",
      "    Target Word : sight\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'away' 'hearing' 'sight' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 20/23\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'hearing' 'power' 'sight' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 21/23\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'power' 'sight' 'surely' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 22/23\n",
      "    Target Word : power\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'power' 'surely' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 23/23\n",
      "    Target Word : thing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'power' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 27/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : men\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'men' 'serve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : serve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'lord' 'men' 'serve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'lord' 'may' 'men' 'serve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : created\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'guard' 'lord' 'may' 'serve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : may\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'evil' 'guard' 'lord' 'may']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : guard\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'evil' 'guard' 'may']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : evil\n",
      "    - Windowing...\n",
      "      Windowing Words : ['evil' 'guard' 'may']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 28/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/17\n",
      "    Target Word : made\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'made' 'resting']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/17\n",
      "    Target Word : earth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'made' 'place' 'resting']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/17\n",
      "    Target Word : resting\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'heaven' 'made' 'place' 'resting']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/17\n",
      "    Target Word : place\n",
      "    - Windowing...\n",
      "      Windowing Words : ['canopy' 'earth' 'heaven' 'place' 'resting']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/17\n",
      "    Target Word : heaven\n",
      "    - Windowing...\n",
      "      Windowing Words : ['canopy' 'heaven' 'place' 'resting' 'sends']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/17\n",
      "    Target Word : canopy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['canopy' 'heaven' 'place' 'rain' 'sends']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/17\n",
      "    Target Word : sends\n",
      "    - Windowing...\n",
      "      Windowing Words : ['canopy' 'cloud' 'heaven' 'rain' 'sends']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/17\n",
      "    Target Word : rain\n",
      "    - Windowing...\n",
      "      Windowing Words : ['brings' 'canopy' 'cloud' 'rain' 'sends']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/17\n",
      "    Target Word : cloud\n",
      "    - Windowing...\n",
      "      Windowing Words : ['brings' 'cloud' 'forth' 'rain' 'sends']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/17\n",
      "    Target Word : brings\n",
      "    - Windowing...\n",
      "      Windowing Words : ['brings' 'cloud' 'forth' 'rain' 'subsistence']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/17\n",
      "    Target Word : forth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['brings' 'cloud' 'forth' 'fruit' 'subsistence']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/17\n",
      "    Target Word : subsistence\n",
      "    - Windowing...\n",
      "      Windowing Words : ['brings' 'forth' 'fruit' 'subsistence' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/17\n",
      "    Target Word : fruit\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forth' 'fruit' 'set' 'subsistence' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/17\n",
      "    Target Word : therefore\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fruit' 'rival' 'set' 'subsistence' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 14/17\n",
      "    Target Word : set\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'fruit' 'rival' 'set' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/17\n",
      "    Target Word : rival\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'know' 'rival' 'set' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/17\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'know' 'rival' 'set']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/17\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'know' 'rival']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 29/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/10\n",
      "    Target Word : doubt\n",
      "    - Windowing...\n",
      "      Windowing Words : ['doubt' 'revealed' 'servant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/10\n",
      "    Target Word : revealed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['doubt' 'produce' 'revealed' 'servant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/10\n",
      "    Target Word : servant\n",
      "    - Windowing...\n",
      "      Windowing Words : ['chapter' 'doubt' 'produce' 'revealed' 'servant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/10\n",
      "    Target Word : produce\n",
      "    - Windowing...\n",
      "      Windowing Words : ['chapter' 'like' 'produce' 'revealed' 'servant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/10\n",
      "    Target Word : chapter\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'chapter' 'like' 'produce' 'servant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/10\n",
      "    Target Word : like\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'chapter' 'like' 'produce' 'witness']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/10\n",
      "    Target Word : call\n",
      "    - Windowing...\n",
      "      Windowing Words : ['besides' 'call' 'chapter' 'like' 'witness']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/10\n",
      "    Target Word : witness\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'besides' 'call' 'like' 'witness']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/10\n",
      "    Target Word : besides\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'besides' 'call' 'truthful' 'witness']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/10\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'besides' 'truthful' 'witness']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/10\n",
      "    Target Word : truthful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'besides' 'truthful']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 30/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/8\n",
      "    Target Word : never\n",
      "    - Windowing...\n",
      "      Windowing Words : ['guard' 'never' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/8\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fire' 'guard' 'never' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/8\n",
      "    Target Word : guard\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fire' 'guard' 'men' 'never' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/8\n",
      "    Target Word : fire\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fire' 'guard' 'men' 'shall' 'stone']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/8\n",
      "    Target Word : men\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fire' 'fuel' 'guard' 'men' 'stone']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/8\n",
      "    Target Word : stone\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fire' 'fuel' 'men' 'prepared' 'stone']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/8\n",
      "    Target Word : fuel\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fuel' 'men' 'prepared' 'stone' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/8\n",
      "    Target Word : prepared\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fuel' 'prepared' 'stone' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/8\n",
      "    Target Word : unbeliever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fuel' 'prepared' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 31/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/27\n",
      "    Target Word : convey\n",
      "    - Windowing...\n",
      "      Windowing Words : ['convey' 'good' 'news']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/27\n",
      "    Target Word : good\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'convey' 'good' 'news']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/27\n",
      "    Target Word : news\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'convey' 'good' 'news']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/27\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'deed' 'good' 'news']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/27\n",
      "    Target Word : good\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'deed' 'good' 'news' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/27\n",
      "    Target Word : deed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'deed' 'garden' 'good' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/27\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['deed' 'garden' 'good' 'river' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/27\n",
      "    Target Word : garden\n",
      "    - Windowing...\n",
      "      Windowing Words : ['deed' 'flow' 'garden' 'river' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/27\n",
      "    Target Word : river\n",
      "    - Windowing...\n",
      "      Windowing Words : ['flow' 'garden' 'river' 'shall' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/27\n",
      "    Target Word : flow\n",
      "    - Windowing...\n",
      "      Windowing Words : ['flow' 'garden' 'river' 'shall' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 10/27\n",
      "    Target Word : whenever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['flow' 'given' 'river' 'shall' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/27\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['flow' 'given' 'portion' 'shall' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/27\n",
      "    Target Word : given\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fruit' 'given' 'portion' 'shall' 'whenever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/27\n",
      "    Target Word : portion\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fruit' 'given' 'portion' 'shall' 'thereof']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/27\n",
      "    Target Word : fruit\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fruit' 'given' 'portion' 'shall' 'thereof']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/27\n",
      "    Target Word : thereof\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fruit' 'portion' 'say' 'shall' 'thereof']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/27\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fruit' 'given' 'say' 'shall' 'thereof']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/27\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'say' 'shall' 'thereof' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/27\n",
      "    Target Word : given\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'say' 'shall' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 19/27\n",
      "    Target Word : u\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'say' 'shall' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 20/27\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'like' 'shall' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 21/27\n",
      "    Target Word : given\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'like' 'shall' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 22/27\n",
      "    Target Word : like\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'like' 'pure' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 23/27\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'like' 'mate' 'pure' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 24/27\n",
      "    Target Word : pure\n",
      "    - Windowing...\n",
      "      Windowing Words : ['like' 'mate' 'pure' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 25/27\n",
      "    Target Word : mate\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abide' 'mate' 'pure' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 26/27\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abide' 'mate' 'pure' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 27/27\n",
      "    Target Word : abide\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abide' 'mate' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 32/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/26\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'ashamed' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/26\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'ashamed' 'set' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/26\n",
      "    Target Word : ashamed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'ashamed' 'forth' 'set' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/26\n",
      "    Target Word : set\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'ashamed' 'forth' 'parable' 'set']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/26\n",
      "    Target Word : forth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ashamed' 'forth' 'gnat' 'parable' 'set']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/26\n",
      "    Target Word : parable\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forth' 'gnat' 'parable' 'set' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/26\n",
      "    Target Word : gnat\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'forth' 'gnat' 'parable' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/26\n",
      "    Target Word : thing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'gnat' 'know' 'parable' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/26\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'gnat' 'know' 'thing' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/26\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'know' 'lord' 'thing' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/26\n",
      "    Target Word : truth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'disbelieve' 'know' 'lord' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/26\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['disbelieve' 'know' 'lord' 'say' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/26\n",
      "    Target Word : disbelieve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'disbelieve' 'lord' 'say' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/26\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'disbelieve' 'lord' 'mean' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/26\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'disbelieve' 'mean' 'parable' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/26\n",
      "    Target Word : mean\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'cause' 'mean' 'parable' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/26\n",
      "    Target Word : parable\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'cause' 'many' 'mean' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 17/26\n",
      "    Target Word : cause\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cause' 'err' 'many' 'mean' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/26\n",
      "    Target Word : many\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cause' 'err' 'many' 'parable']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 19/26\n",
      "    Target Word : err\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cause' 'err' 'lead' 'many']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 20/26\n",
      "    Target Word : many\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'err' 'lead' 'many']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 21/26\n",
      "    Target Word : lead\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'cause' 'err' 'lead' 'many']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 22/26\n",
      "    Target Word : aright\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'cause' 'err' 'lead' 'many']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 23/26\n",
      "    Target Word : cause\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'cause' 'err' 'except' 'lead']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 24/26\n",
      "    Target Word : err\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'cause' 'err' 'except' 'transgressor']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 25/26\n",
      "    Target Word : except\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cause' 'err' 'except' 'transgressor']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 26/26\n",
      "    Target Word : transgressor\n",
      "    - Windowing...\n",
      "      Windowing Words : ['err' 'except' 'transgressor']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 33/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/12\n",
      "    Target Word : break\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'break' 'covenant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/12\n",
      "    Target Word : covenant\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'break' 'confirmation' 'covenant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/12\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'break' 'confirmation' 'covenant' 'cut']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/12\n",
      "    Target Word : confirmation\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'asunder' 'confirmation' 'covenant' 'cut']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/12\n",
      "    Target Word : cut\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'asunder' 'confirmation' 'cut']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/12\n",
      "    Target Word : asunder\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'asunder' 'confirmation' 'cut' 'ordered']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/12\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'asunder' 'cut' 'joined' 'ordered']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/12\n",
      "    Target Word : ordered\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'asunder' 'joined' 'make' 'ordered']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/12\n",
      "    Target Word : joined\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'joined' 'make' 'mischief' 'ordered']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/12\n",
      "    Target Word : make\n",
      "    - Windowing...\n",
      "      Windowing Words : ['joined' 'land' 'make' 'mischief' 'ordered']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/12\n",
      "    Target Word : mischief\n",
      "    - Windowing...\n",
      "      Windowing Words : ['joined' 'land' 'loser' 'make' 'mischief']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/12\n",
      "    Target Word : land\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'loser' 'make' 'mischief']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/12\n",
      "    Target Word : loser\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'loser' 'mischief']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 34/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/11\n",
      "    Target Word : deny\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'dead' 'deny']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/11\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'dead' 'deny' 'gave']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/11\n",
      "    Target Word : dead\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'dead' 'deny' 'gave' 'life']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/11\n",
      "    Target Word : gave\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'cause' 'dead' 'gave' 'life']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/11\n",
      "    Target Word : life\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cause' 'dead' 'die' 'gave' 'life']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/11\n",
      "    Target Word : cause\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bring' 'cause' 'die' 'gave' 'life']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/11\n",
      "    Target Word : die\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bring' 'cause' 'die' 'life']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/11\n",
      "    Target Word : bring\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bring' 'cause' 'die' 'life' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/11\n",
      "    Target Word : life\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bring' 'brought' 'die' 'life' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/11\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'bring' 'brought' 'life' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/11\n",
      "    Target Word : brought\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'brought' 'life' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 11/11\n",
      "    Target Word : back\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'brought' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 35/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/9\n",
      "    Target Word : created\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'directed' 'earth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/9\n",
      "    Target Word : earth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'directed' 'earth' 'heaven']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/9\n",
      "    Target Word : directed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['created' 'directed' 'earth' 'heaven' 'made']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/9\n",
      "    Target Word : heaven\n",
      "    - Windowing...\n",
      "      Windowing Words : ['complete' 'directed' 'earth' 'heaven' 'made']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/9\n",
      "    Target Word : made\n",
      "    - Windowing...\n",
      "      Windowing Words : ['complete' 'directed' 'heaven' 'made' 'seven']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/9\n",
      "    Target Word : complete\n",
      "    - Windowing...\n",
      "      Windowing Words : ['complete' 'heaven' 'made' 'seven']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/9\n",
      "    Target Word : seven\n",
      "    - Windowing...\n",
      "      Windowing Words : ['complete' 'heaven' 'know' 'made' 'seven']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/9\n",
      "    Target Word : heaven\n",
      "    - Windowing...\n",
      "      Windowing Words : ['complete' 'heaven' 'know' 'seven' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/9\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['heaven' 'know' 'seven' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/9\n",
      "    Target Word : thing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['heaven' 'know' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 36/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/25\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'lord' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/25\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'going' 'lord' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/25\n",
      "    Target Word : angel\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'going' 'lord' 'place' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/25\n",
      "    Target Word : going\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'earth' 'going' 'place' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/25\n",
      "    Target Word : place\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'earth' 'going' 'khalif' 'place']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/25\n",
      "    Target Word : earth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'going' 'khalif' 'place' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/25\n",
      "    Target Word : khalif\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'khalif' 'place' 'said' 'wilt']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/25\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'khalif' 'said' 'thou' 'wilt']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/25\n",
      "    Target Word : wilt\n",
      "    - Windowing...\n",
      "      Windowing Words : ['khalif' 'place' 'said' 'thou' 'wilt']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/25\n",
      "    Target Word : thou\n",
      "    - Windowing...\n",
      "      Windowing Words : ['place' 'said' 'shall' 'thou' 'wilt']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/25\n",
      "    Target Word : place\n",
      "    - Windowing...\n",
      "      Windowing Words : ['make' 'place' 'shall' 'thou' 'wilt']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/25\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['make' 'mischief' 'place' 'shall' 'thou']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/25\n",
      "    Target Word : make\n",
      "    - Windowing...\n",
      "      Windowing Words : ['make' 'mischief' 'place' 'shall' 'shed']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/25\n",
      "    Target Word : mischief\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blood' 'make' 'mischief' 'shall' 'shed']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/25\n",
      "    Target Word : shed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blood' 'celebrate' 'make' 'mischief' 'shed']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/25\n",
      "    Target Word : blood\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blood' 'celebrate' 'mischief' 'shed' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/25\n",
      "    Target Word : celebrate\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blood' 'celebrate' 'praise' 'shed' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/25\n",
      "    Target Word : thy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['blood' 'celebrate' 'extol' 'praise' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/25\n",
      "    Target Word : praise\n",
      "    - Windowing...\n",
      "      Windowing Words : ['celebrate' 'extol' 'praise' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 19/25\n",
      "    Target Word : extol\n",
      "    - Windowing...\n",
      "      Windowing Words : ['extol' 'holiness' 'praise' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 20/25\n",
      "    Target Word : thy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['extol' 'holiness' 'praise' 'said' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 21/25\n",
      "    Target Word : holiness\n",
      "    - Windowing...\n",
      "      Windowing Words : ['extol' 'holiness' 'said' 'surely' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 22/25\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['holiness' 'know' 'said' 'surely' 'thy']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 23/25\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['holiness' 'know' 'said' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 24/25\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['know' 'said' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 25/25\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['know' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 37/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/8\n",
      "    Target Word : taught\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'name' 'taught']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/8\n",
      "    Target Word : adam\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'name' 'presented' 'taught']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/8\n",
      "    Target Word : name\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'angel' 'name' 'presented' 'taught']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/8\n",
      "    Target Word : presented\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'angel' 'name' 'presented' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/8\n",
      "    Target Word : angel\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'name' 'presented' 'said' 'tell']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/8\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'name' 'presented' 'said' 'tell']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/8\n",
      "    Target Word : tell\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'name' 'right' 'said' 'tell']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/8\n",
      "    Target Word : name\n",
      "    - Windowing...\n",
      "      Windowing Words : ['name' 'right' 'said' 'tell']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/8\n",
      "    Target Word : right\n",
      "    - Windowing...\n",
      "      Windowing Words : ['name' 'right' 'tell']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 38/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/12\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['glory' 'said' 'thee']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/12\n",
      "    Target Word : glory\n",
      "    - Windowing...\n",
      "      Windowing Words : ['glory' 'knowledge' 'said' 'thee']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/12\n",
      "    Target Word : thee\n",
      "    - Windowing...\n",
      "      Windowing Words : ['glory' 'knowledge' 'said' 'thee' 'thou']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/12\n",
      "    Target Word : knowledge\n",
      "    - Windowing...\n",
      "      Windowing Words : ['glory' 'hast' 'knowledge' 'thee' 'thou']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/12\n",
      "    Target Word : thou\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hast' 'knowledge' 'taught' 'thee' 'thou']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/12\n",
      "    Target Word : hast\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hast' 'knowledge' 'taught' 'thou' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/12\n",
      "    Target Word : taught\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hast' 'surely' 'taught' 'thou' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/12\n",
      "    Target Word : u\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hast' 'surely' 'taught' 'thou' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/12\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['art' 'surely' 'taught' 'thou' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/12\n",
      "    Target Word : thou\n",
      "    - Windowing...\n",
      "      Windowing Words : ['art' 'knowing' 'surely' 'thou' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/12\n",
      "    Target Word : art\n",
      "    - Windowing...\n",
      "      Windowing Words : ['art' 'knowing' 'surely' 'thou' 'wise']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/12\n",
      "    Target Word : knowing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['art' 'knowing' 'thou' 'wise']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/12\n",
      "    Target Word : wise\n",
      "    - Windowing...\n",
      "      Windowing Words : ['art' 'knowing' 'wise']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 39/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/15\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'inform' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/15\n",
      "    Target Word : adam\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'inform' 'name' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/15\n",
      "    Target Word : inform\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'inform' 'informed' 'name' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/15\n",
      "    Target Word : name\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'inform' 'informed' 'name']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/15\n",
      "    Target Word : informed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['inform' 'informed' 'name' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/15\n",
      "    Target Word : name\n",
      "    - Windowing...\n",
      "      Windowing Words : ['informed' 'name' 'said' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/15\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['informed' 'name' 'said' 'say' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/15\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['know' 'name' 'said' 'say' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/15\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ghaib' 'know' 'said' 'say' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/15\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ghaib' 'heaven' 'know' 'say' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 10/15\n",
      "    Target Word : ghaib\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'ghaib' 'heaven' 'know' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/15\n",
      "    Target Word : heaven\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'ghaib' 'heaven' 'know']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/15\n",
      "    Target Word : earth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'ghaib' 'heaven' 'know' 'manifest']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/15\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'heaven' 'hide' 'know' 'manifest']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/15\n",
      "    Target Word : manifest\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'hide' 'know' 'manifest']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/15\n",
      "    Target Word : hide\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hide' 'know' 'manifest']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 40/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/10\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'make' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/10\n",
      "    Target Word : angel\n",
      "    - Windowing...\n",
      "      Windowing Words : ['angel' 'make' 'obeisance' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/10\n",
      "    Target Word : make\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'angel' 'make' 'obeisance' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/10\n",
      "    Target Word : obeisance\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'angel' 'make' 'obeisance']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/10\n",
      "    Target Word : adam\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'iblis' 'make' 'obeisance']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/10\n",
      "    Target Word : obeisance\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'iblis' 'obeisance' 'refused']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/10\n",
      "    Target Word : iblis\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'iblis' 'obeisance' 'proud' 'refused']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/10\n",
      "    Target Word : refused\n",
      "    - Windowing...\n",
      "      Windowing Words : ['iblis' 'obeisance' 'one' 'proud' 'refused']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/10\n",
      "    Target Word : proud\n",
      "    - Windowing...\n",
      "      Windowing Words : ['iblis' 'one' 'proud' 'refused' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/10\n",
      "    Target Word : one\n",
      "    - Windowing...\n",
      "      Windowing Words : ['one' 'proud' 'refused' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/10\n",
      "    Target Word : unbeliever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['one' 'proud' 'unbeliever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 41/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/12\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'dwell' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/12\n",
      "    Target Word : adam\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'dwell' 'said' 'wife']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/12\n",
      "    Target Word : dwell\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'dwell' 'garden' 'said' 'wife']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/12\n",
      "    Target Word : wife\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'dwell' 'eat' 'garden' 'wife']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/12\n",
      "    Target Word : garden\n",
      "    - Windowing...\n",
      "      Windowing Words : ['dwell' 'eat' 'garden' 'plenteous' 'wife']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/12\n",
      "    Target Word : eat\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'food' 'garden' 'plenteous' 'wife']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/12\n",
      "    Target Word : plenteous\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'food' 'garden' 'plenteous' 'wherever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/12\n",
      "    Target Word : food\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'food' 'plenteous' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/12\n",
      "    Target Word : wherever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['approach' 'food' 'plenteous' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/12\n",
      "    Target Word : wish\n",
      "    - Windowing...\n",
      "      Windowing Words : ['approach' 'food' 'tree' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/12\n",
      "    Target Word : approach\n",
      "    - Windowing...\n",
      "      Windowing Words : ['approach' 'tree' 'unjust' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/12\n",
      "    Target Word : tree\n",
      "    - Windowing...\n",
      "      Windowing Words : ['approach' 'tree' 'unjust' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/12\n",
      "    Target Word : unjust\n",
      "    - Windowing...\n",
      "      Windowing Words : ['approach' 'tree' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 42/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/14\n",
      "    Target Word : shaitan\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fall' 'made' 'shaitan']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/14\n",
      "    Target Word : made\n",
      "    - Windowing...\n",
      "      Windowing Words : ['caused' 'fall' 'made' 'shaitan']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/14\n",
      "    Target Word : fall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['caused' 'depart' 'fall' 'made' 'shaitan']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/14\n",
      "    Target Word : caused\n",
      "    - Windowing...\n",
      "      Windowing Words : ['caused' 'depart' 'fall' 'made' 'state']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 4/14\n",
      "    Target Word : depart\n",
      "    - Windowing...\n",
      "      Windowing Words : ['caused' 'depart' 'fall' 'said' 'state']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/14\n",
      "    Target Word : state\n",
      "    - Windowing...\n",
      "      Windowing Words : ['caused' 'depart' 'get' 'said' 'state']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/14\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['depart' 'forth' 'get' 'said' 'state']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/14\n",
      "    Target Word : get\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enemy' 'forth' 'get' 'said' 'state']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/14\n",
      "    Target Word : forth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enemy' 'forth' 'get' 'others' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/14\n",
      "    Target Word : enemy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'enemy' 'forth' 'get' 'others']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/14\n",
      "    Target Word : others\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abode' 'earth' 'enemy' 'forth' 'others']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/14\n",
      "    Target Word : earth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abode' 'earth' 'enemy' 'others' 'provision']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/14\n",
      "    Target Word : abode\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abode' 'earth' 'others' 'provision' 'time']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/14\n",
      "    Target Word : provision\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abode' 'earth' 'provision' 'time']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/14\n",
      "    Target Word : time\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abode' 'provision' 'time']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 43/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/10\n",
      "    Target Word : adam\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'received' 'word']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/10\n",
      "    Target Word : received\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'lord' 'received' 'word']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/10\n",
      "    Target Word : word\n",
      "    - Windowing...\n",
      "      Windowing Words : ['adam' 'lord' 'received' 'turned' 'word']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/10\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'mercifully' 'received' 'turned' 'word']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/10\n",
      "    Target Word : turned\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'mercifully' 'surely' 'turned' 'word']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/10\n",
      "    Target Word : mercifully\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'mercifully' 'oft' 'surely' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/10\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['mercifully' 'oft' 'returning' 'surely' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/10\n",
      "    Target Word : oft\n",
      "    - Windowing...\n",
      "      Windowing Words : ['mercifully' 'mercy' 'oft' 'returning' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/10\n",
      "    Target Word : returning\n",
      "    - Windowing...\n",
      "      Windowing Words : ['merciful' 'mercy' 'oft' 'returning' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/10\n",
      "    Target Word : mercy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['merciful' 'mercy' 'oft' 'returning']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/10\n",
      "    Target Word : merciful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['merciful' 'mercy' 'returning']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 44/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/15\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forth' 'go' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/15\n",
      "    Target Word : go\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forth' 'go' 'said' 'state']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/15\n",
      "    Target Word : forth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forth' 'go' 'said' 'state' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/15\n",
      "    Target Word : state\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'forth' 'go' 'state' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/15\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'forth' 'guidance' 'state' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/15\n",
      "    Target Word : come\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'guidance' 'state' 'surely' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/15\n",
      "    Target Word : guidance\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'follows' 'guidance' 'surely' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/15\n",
      "    Target Word : whoever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'follows' 'guidance' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/15\n",
      "    Target Word : follows\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fear' 'follows' 'guidance' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/15\n",
      "    Target Word : guidance\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fear' 'follows' 'guidance' 'shall' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/15\n",
      "    Target Word : fear\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'fear' 'follows' 'guidance' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/15\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'fear' 'guidance' 'shall' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 12/15\n",
      "    Target Word : come\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'fear' 'shall' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/15\n",
      "    Target Word : upon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'grieve' 'shall' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/15\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['come' 'grieve' 'shall' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/15\n",
      "    Target Word : grieve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['grieve' 'shall' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 45/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : disbelieve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['communication' 'disbelieve' 'reject']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : reject\n",
      "    - Windowing...\n",
      "      Windowing Words : ['communication' 'disbelieve' 'inmate' 'reject']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : communication\n",
      "    - Windowing...\n",
      "      Windowing Words : ['communication' 'disbelieve' 'fire' 'inmate' 'reject']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : inmate\n",
      "    - Windowing...\n",
      "      Windowing Words : ['communication' 'fire' 'inmate' 'reject' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : fire\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abide' 'communication' 'fire' 'inmate' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abide' 'fire' 'inmate' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : abide\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abide' 'fire' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 46/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/11\n",
      "    Target Word : child\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'child' 'israel']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/11\n",
      "    Target Word : israel\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'child' 'israel' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/11\n",
      "    Target Word : call\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'child' 'favor' 'israel' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/11\n",
      "    Target Word : mind\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'call' 'favor' 'israel' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/11\n",
      "    Target Word : favor\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'call' 'faithful' 'favor' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/11\n",
      "    Target Word : bestowed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'covenant' 'faithful' 'favor' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/11\n",
      "    Target Word : faithful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'covenant' 'faithful' 'favor' 'fulfill']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/11\n",
      "    Target Word : covenant\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'covenant' 'faithful' 'fulfill']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/11\n",
      "    Target Word : fulfill\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'covenant' 'faithful' 'fulfill']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/11\n",
      "    Target Word : covenant\n",
      "    - Windowing...\n",
      "      Windowing Words : ['afraid' 'alone' 'covenant' 'fulfill']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/11\n",
      "    Target Word : alone\n",
      "    - Windowing...\n",
      "      Windowing Words : ['afraid' 'alone' 'covenant' 'fulfill']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/11\n",
      "    Target Word : afraid\n",
      "    - Windowing...\n",
      "      Windowing Words : ['afraid' 'alone' 'covenant']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 47/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/12\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'revealed' 'verifying']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/12\n",
      "    Target Word : revealed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'first' 'revealed' 'verifying']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/12\n",
      "    Target Word : verifying\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'deny' 'first' 'revealed' 'verifying']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/12\n",
      "    Target Word : first\n",
      "    - Windowing...\n",
      "      Windowing Words : ['deny' 'first' 'neither' 'revealed' 'verifying']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/12\n",
      "    Target Word : deny\n",
      "    - Windowing...\n",
      "      Windowing Words : ['deny' 'first' 'neither' 'take' 'verifying']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/12\n",
      "    Target Word : neither\n",
      "    - Windowing...\n",
      "      Windowing Words : ['deny' 'first' 'mean' 'neither' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/12\n",
      "    Target Word : take\n",
      "    - Windowing...\n",
      "      Windowing Words : ['deny' 'mean' 'neither' 'price' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/12\n",
      "    Target Word : mean\n",
      "    - Windowing...\n",
      "      Windowing Words : ['exchange' 'mean' 'neither' 'price' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/12\n",
      "    Target Word : price\n",
      "    - Windowing...\n",
      "      Windowing Words : ['communication' 'exchange' 'mean' 'price' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/12\n",
      "    Target Word : exchange\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'communication' 'exchange' 'mean' 'price']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 10/12\n",
      "    Target Word : communication\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'communication' 'exchange' 'fear' 'price']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/12\n",
      "    Target Word : alone\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'communication' 'exchange' 'fear']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/12\n",
      "    Target Word : fear\n",
      "    - Windowing...\n",
      "      Windowing Words : ['alone' 'communication' 'fear']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 48/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/5\n",
      "    Target Word : mix\n",
      "    - Windowing...\n",
      "      Windowing Words : ['falsehood' 'mix' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/5\n",
      "    Target Word : truth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['falsehood' 'hide' 'mix' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/5\n",
      "    Target Word : falsehood\n",
      "    - Windowing...\n",
      "      Windowing Words : ['falsehood' 'hide' 'mix' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/5\n",
      "    Target Word : hide\n",
      "    - Windowing...\n",
      "      Windowing Words : ['falsehood' 'hide' 'know' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/5\n",
      "    Target Word : truth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['falsehood' 'hide' 'know' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/5\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hide' 'know' 'truth']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 49/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : keep\n",
      "    - Windowing...\n",
      "      Windowing Words : ['keep' 'pay' 'prayer']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : prayer\n",
      "    - Windowing...\n",
      "      Windowing Words : ['keep' 'pay' 'poor' 'prayer']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : pay\n",
      "    - Windowing...\n",
      "      Windowing Words : ['keep' 'pay' 'poor' 'prayer' 'rate']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : poor\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bow' 'pay' 'poor' 'prayer' 'rate']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : rate\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bow' 'pay' 'poor' 'rate']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : bow\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bow' 'poor' 'rate']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : bow\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bow' 'rate']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 50/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/7\n",
      "    Target Word : enjoin\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enjoin' 'good' 'men']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/7\n",
      "    Target Word : men\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enjoin' 'good' 'men' 'neglect']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/7\n",
      "    Target Word : good\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enjoin' 'good' 'men' 'neglect' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/7\n",
      "    Target Word : neglect\n",
      "    - Windowing...\n",
      "      Windowing Words : ['good' 'men' 'neglect' 'read' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/7\n",
      "    Target Word : soul\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'good' 'neglect' 'read' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/7\n",
      "    Target Word : read\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'neglect' 'read' 'sense' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/7\n",
      "    Target Word : book\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'read' 'sense' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/7\n",
      "    Target Word : sense\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'read' 'sense']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 51/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/9\n",
      "    Target Word : seek\n",
      "    - Windowing...\n",
      "      Windowing Words : ['assistance' 'patience' 'seek']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/9\n",
      "    Target Word : assistance\n",
      "    - Windowing...\n",
      "      Windowing Words : ['assistance' 'patience' 'prayer' 'seek']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/9\n",
      "    Target Word : patience\n",
      "    - Windowing...\n",
      "      Windowing Words : ['assistance' 'patience' 'prayer' 'seek' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/9\n",
      "    Target Word : prayer\n",
      "    - Windowing...\n",
      "      Windowing Words : ['assistance' 'hard' 'patience' 'prayer' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/9\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hard' 'patience' 'prayer' 'surely' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/9\n",
      "    Target Word : hard\n",
      "    - Windowing...\n",
      "      Windowing Words : ['except' 'hard' 'prayer' 'surely' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/9\n",
      "    Target Word : thing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['except' 'hard' 'humble' 'surely' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/9\n",
      "    Target Word : except\n",
      "    - Windowing...\n",
      "      Windowing Words : ['except' 'hard' 'humble' 'one' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/9\n",
      "    Target Word : humble\n",
      "    - Windowing...\n",
      "      Windowing Words : ['except' 'humble' 'one' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/9\n",
      "    Target Word : one\n",
      "    - Windowing...\n",
      "      Windowing Words : ['except' 'humble' 'one']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "==== AYAT - 52/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/5\n",
      "    Target Word : know\n",
      "    - Windowing...\n",
      "      Windowing Words : ['know' 'meet' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/5\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['know' 'lord' 'meet' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/5\n",
      "    Target Word : meet\n",
      "    - Windowing...\n",
      "      Windowing Words : ['know' 'lord' 'meet' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/5\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'meet' 'return' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/5\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'meet' 'return' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/5\n",
      "    Target Word : return\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lord' 'return' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 53/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/8\n",
      "    Target Word : child\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'child' 'israel']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/8\n",
      "    Target Word : israel\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'child' 'israel' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/8\n",
      "    Target Word : call\n",
      "    - Windowing...\n",
      "      Windowing Words : ['call' 'child' 'favor' 'israel' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/8\n",
      "    Target Word : mind\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'call' 'favor' 'israel' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/8\n",
      "    Target Word : favor\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'call' 'favor' 'made' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/8\n",
      "    Target Word : bestowed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'excel' 'favor' 'made' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/8\n",
      "    Target Word : made\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'excel' 'favor' 'made' 'nation']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/8\n",
      "    Target Word : excel\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bestowed' 'excel' 'made' 'nation']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/8\n",
      "    Target Word : nation\n",
      "    - Windowing...\n",
      "      Windowing Words : ['excel' 'made' 'nation']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 54/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/17\n",
      "    Target Word : guard\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'guard' 'one']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/17\n",
      "    Target Word : day\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'guard' 'one' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/17\n",
      "    Target Word : one\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'guard' 'one' 'shall' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/17\n",
      "    Target Word : soul\n",
      "    - Windowing...\n",
      "      Windowing Words : ['avail' 'day' 'one' 'shall' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/17\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['another' 'avail' 'one' 'shall' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/17\n",
      "    Target Word : avail\n",
      "    - Windowing...\n",
      "      Windowing Words : ['another' 'avail' 'least' 'shall' 'soul']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/17\n",
      "    Target Word : another\n",
      "    - Windowing...\n",
      "      Windowing Words : ['another' 'avail' 'least' 'neither' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/17\n",
      "    Target Word : least\n",
      "    - Windowing...\n",
      "      Windowing Words : ['another' 'avail' 'least' 'neither' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/17\n",
      "    Target Word : neither\n",
      "    - Windowing...\n",
      "      Windowing Words : ['another' 'intercession' 'least' 'neither' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/17\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['behalf' 'intercession' 'least' 'neither' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/17\n",
      "    Target Word : intercession\n",
      "    - Windowing...\n",
      "      Windowing Words : ['accepted' 'behalf' 'intercession' 'neither' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/17\n",
      "    Target Word : behalf\n",
      "    - Windowing...\n",
      "      Windowing Words : ['accepted' 'behalf' 'intercession' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/17\n",
      "    Target Word : accepted\n",
      "    - Windowing...\n",
      "      Windowing Words : ['accepted' 'behalf' 'compensation' 'intercession' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/17\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['accepted' 'behalf' 'compensation' 'shall' 'taken']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/17\n",
      "    Target Word : compensation\n",
      "    - Windowing...\n",
      "      Windowing Words : ['accepted' 'compensation' 'shall' 'taken']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/17\n",
      "    Target Word : taken\n",
      "    - Windowing...\n",
      "      Windowing Words : ['compensation' 'helped' 'shall' 'taken']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/17\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['compensation' 'helped' 'shall' 'taken']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/17\n",
      "    Target Word : helped\n",
      "    - Windowing...\n",
      "      Windowing Words : ['helped' 'shall' 'taken']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 55/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Target Word : delivered\n",
      "    - Windowing...\n",
      "      Windowing Words : ['delivered' 'firon' 'people']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/12\n",
      "    Target Word : firon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['delivered' 'firon' 'people' 'subjected']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/12\n",
      "    Target Word : people\n",
      "    - Windowing...\n",
      "      Windowing Words : ['delivered' 'firon' 'people' 'severe' 'subjected']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/12\n",
      "    Target Word : subjected\n",
      "    - Windowing...\n",
      "      Windowing Words : ['firon' 'people' 'severe' 'subjected' 'torment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/12\n",
      "    Target Word : severe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['killing' 'people' 'severe' 'subjected' 'torment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/12\n",
      "    Target Word : torment\n",
      "    - Windowing...\n",
      "      Windowing Words : ['killing' 'severe' 'son' 'subjected' 'torment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/12\n",
      "    Target Word : killing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['killing' 'severe' 'son' 'sparing' 'torment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/12\n",
      "    Target Word : son\n",
      "    - Windowing...\n",
      "      Windowing Words : ['killing' 'son' 'sparing' 'torment' 'woman']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/12\n",
      "    Target Word : sparing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['great' 'killing' 'son' 'sparing' 'woman']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/12\n",
      "    Target Word : woman\n",
      "    - Windowing...\n",
      "      Windowing Words : ['great' 'son' 'sparing' 'trial' 'woman']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/12\n",
      "    Target Word : great\n",
      "    - Windowing...\n",
      "      Windowing Words : ['great' 'lord' 'sparing' 'trial' 'woman']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/12\n",
      "    Target Word : trial\n",
      "    - Windowing...\n",
      "      Windowing Words : ['great' 'lord' 'trial' 'woman']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/12\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['great' 'lord' 'trial']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 56/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : parted\n",
      "    - Windowing...\n",
      "      Windowing Words : ['parted' 'saved' 'sea']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : sea\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drowned' 'parted' 'saved' 'sea']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : saved\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drowned' 'follower' 'parted' 'saved' 'sea']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : drowned\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drowned' 'firon' 'follower' 'saved' 'sea']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : follower\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drowned' 'firon' 'follower' 'saved' 'watched']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : firon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drowned' 'firon' 'follower' 'watched']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : watched\n",
      "    - Windowing...\n",
      "      Windowing Words : ['firon' 'follower' 'watched']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 57/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/8\n",
      "    Target Word : appointed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['appointed' 'forty' 'time']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/8\n",
      "    Target Word : time\n",
      "    - Windowing...\n",
      "      Windowing Words : ['appointed' 'forty' 'night' 'time']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/8\n",
      "    Target Word : forty\n",
      "    - Windowing...\n",
      "      Windowing Words : ['appointed' 'forty' 'musa' 'night' 'time']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/8\n",
      "    Target Word : night\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forty' 'musa' 'night' 'time' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/8\n",
      "    Target Word : musa\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'forty' 'musa' 'night' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/8\n",
      "    Target Word : took\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'god' 'musa' 'night' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/8\n",
      "    Target Word : calf\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'god' 'musa' 'took' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/8\n",
      "    Target Word : god\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'god' 'took' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/8\n",
      "    Target Word : unjust\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'god' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 58/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/3\n",
      "    Target Word : pardoned\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'might' 'pardoned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/3\n",
      "    Target Word : might\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'might' 'pardoned' 'thanks']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/3\n",
      "    Target Word : give\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'might' 'pardoned' 'thanks']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/3\n",
      "    Target Word : thanks\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'might' 'thanks']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 59/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/6\n",
      "    Target Word : gave\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'gave' 'musa']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 1/6\n",
      "    Target Word : musa\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'distinction' 'gave' 'musa']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/6\n",
      "    Target Word : book\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'distinction' 'gave' 'might' 'musa']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/6\n",
      "    Target Word : distinction\n",
      "    - Windowing...\n",
      "      Windowing Words : ['book' 'distinction' 'might' 'musa' 'walk']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/6\n",
      "    Target Word : might\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'book' 'distinction' 'might' 'walk']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/6\n",
      "    Target Word : walk\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'distinction' 'might' 'walk']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/6\n",
      "    Target Word : aright\n",
      "    - Windowing...\n",
      "      Windowing Words : ['aright' 'might' 'walk']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 60/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/23\n",
      "    Target Word : musa\n",
      "    - Windowing...\n",
      "      Windowing Words : ['musa' 'people' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/23\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['musa' 'people' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/23\n",
      "    Target Word : people\n",
      "    - Windowing...\n",
      "      Windowing Words : ['musa' 'people' 'said' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/23\n",
      "    Target Word : people\n",
      "    - Windowing...\n",
      "      Windowing Words : ['people' 'said' 'surely' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/23\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['people' 'surely' 'taking' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/23\n",
      "    Target Word : unjust\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'people' 'surely' 'taking' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/23\n",
      "    Target Word : taking\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'god' 'surely' 'taking' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/23\n",
      "    Target Word : calf\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'god' 'taking' 'therefore' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/23\n",
      "    Target Word : god\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'god' 'taking' 'therefore' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/23\n",
      "    Target Word : therefore\n",
      "    - Windowing...\n",
      "      Windowing Words : ['calf' 'creator' 'god' 'therefore' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/23\n",
      "    Target Word : turn\n",
      "    - Windowing...\n",
      "      Windowing Words : ['creator' 'god' 'penitently' 'therefore' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/23\n",
      "    Target Word : creator\n",
      "    - Windowing...\n",
      "      Windowing Words : ['creator' 'kill' 'penitently' 'therefore' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/23\n",
      "    Target Word : penitently\n",
      "    - Windowing...\n",
      "      Windowing Words : ['creator' 'kill' 'penitently' 'people' 'turn']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/23\n",
      "    Target Word : kill\n",
      "    - Windowing...\n",
      "      Windowing Words : ['best' 'creator' 'kill' 'penitently' 'people']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/23\n",
      "    Target Word : people\n",
      "    - Windowing...\n",
      "      Windowing Words : ['best' 'creator' 'kill' 'penitently' 'people']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/23\n",
      "    Target Word : best\n",
      "    - Windowing...\n",
      "      Windowing Words : ['best' 'creator' 'kill' 'people' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/23\n",
      "    Target Word : creator\n",
      "    - Windowing...\n",
      "      Windowing Words : ['best' 'creator' 'mercifully' 'people' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/23\n",
      "    Target Word : turned\n",
      "    - Windowing...\n",
      "      Windowing Words : ['best' 'creator' 'mercifully' 'surely' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/23\n",
      "    Target Word : mercifully\n",
      "    - Windowing...\n",
      "      Windowing Words : ['creator' 'mercifully' 'oft' 'surely' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 19/23\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['mercifully' 'oft' 'returning' 'surely' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 20/23\n",
      "    Target Word : oft\n",
      "    - Windowing...\n",
      "      Windowing Words : ['mercifully' 'mercy' 'oft' 'returning' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 21/23\n",
      "    Target Word : returning\n",
      "    - Windowing...\n",
      "      Windowing Words : ['merciful' 'mercy' 'oft' 'returning' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 22/23\n",
      "    Target Word : mercy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['merciful' 'mercy' 'oft' 'returning']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 23/23\n",
      "    Target Word : merciful\n",
      "    - Windowing...\n",
      "      Windowing Words : ['merciful' 'mercy' 'returning']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 61/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/8\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'musa' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/8\n",
      "    Target Word : musa\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'musa' 'said' 'see']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/8\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'musa' 'said' 'see']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/8\n",
      "    Target Word : see\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'manifestly' 'musa' 'see']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 4/8\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'believe' 'manifestly' 'punishment' 'see']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/8\n",
      "    Target Word : manifestly\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'manifestly' 'overtook' 'punishment' 'see']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/8\n",
      "    Target Word : punishment\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'looked' 'manifestly' 'overtook' 'punishment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/8\n",
      "    Target Word : overtook\n",
      "    - Windowing...\n",
      "      Windowing Words : ['looked' 'manifestly' 'overtook' 'punishment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/8\n",
      "    Target Word : looked\n",
      "    - Windowing...\n",
      "      Windowing Words : ['looked' 'overtook' 'punishment']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 62/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/4\n",
      "    Target Word : raised\n",
      "    - Windowing...\n",
      "      Windowing Words : ['death' 'may' 'raised']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/4\n",
      "    Target Word : death\n",
      "    - Windowing...\n",
      "      Windowing Words : ['death' 'give' 'may' 'raised']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/4\n",
      "    Target Word : may\n",
      "    - Windowing...\n",
      "      Windowing Words : ['death' 'give' 'may' 'raised' 'thanks']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/4\n",
      "    Target Word : give\n",
      "    - Windowing...\n",
      "      Windowing Words : ['death' 'give' 'may' 'thanks']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/4\n",
      "    Target Word : thanks\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'may' 'thanks']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 63/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/16\n",
      "    Target Word : made\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cloud' 'give' 'made']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/16\n",
      "    Target Word : cloud\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cloud' 'give' 'made' 'shade']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/16\n",
      "    Target Word : give\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cloud' 'give' 'made' 'sent' 'shade']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/16\n",
      "    Target Word : shade\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cloud' 'give' 'manna' 'sent' 'shade']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/16\n",
      "    Target Word : sent\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'manna' 'quail' 'sent' 'shade']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/16\n",
      "    Target Word : manna\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'manna' 'quail' 'sent' 'shade']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/16\n",
      "    Target Word : quail\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'good' 'manna' 'quail' 'sent']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/16\n",
      "    Target Word : eat\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'good' 'manna' 'quail' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/16\n",
      "    Target Word : good\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'given' 'good' 'quail' 'thing']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/16\n",
      "    Target Word : thing\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'given' 'good' 'thing' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/16\n",
      "    Target Word : given\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'good' 'harm' 'thing' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/16\n",
      "    Target Word : u\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'harm' 'made' 'thing' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/16\n",
      "    Target Word : harm\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'harm' 'made' 'soul' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/16\n",
      "    Target Word : made\n",
      "    - Windowing...\n",
      "      Windowing Words : ['harm' 'made' 'soul' 'suffer' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/16\n",
      "    Target Word : soul\n",
      "    - Windowing...\n",
      "      Windowing Words : ['harm' 'loss' 'made' 'soul' 'suffer']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/16\n",
      "    Target Word : suffer\n",
      "    - Windowing...\n",
      "      Windowing Words : ['loss' 'made' 'soul' 'suffer']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/16\n",
      "    Target Word : loss\n",
      "    - Windowing...\n",
      "      Windowing Words : ['loss' 'soul' 'suffer']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 64/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/18\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['city' 'enter' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/18\n",
      "    Target Word : enter\n",
      "    - Windowing...\n",
      "      Windowing Words : ['city' 'eat' 'enter' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/18\n",
      "    Target Word : city\n",
      "    - Windowing...\n",
      "      Windowing Words : ['city' 'eat' 'enter' 'plenteous' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/18\n",
      "    Target Word : eat\n",
      "    - Windowing...\n",
      "      Windowing Words : ['city' 'eat' 'enter' 'food' 'plenteous']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/18\n",
      "    Target Word : plenteous\n",
      "    - Windowing...\n",
      "      Windowing Words : ['city' 'eat' 'food' 'plenteous' 'wherever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/18\n",
      "    Target Word : food\n",
      "    - Windowing...\n",
      "      Windowing Words : ['eat' 'food' 'plenteous' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/18\n",
      "    Target Word : wherever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enter' 'food' 'plenteous' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 7/18\n",
      "    Target Word : wish\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enter' 'food' 'gate' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/18\n",
      "    Target Word : enter\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enter' 'gate' 'making' 'wherever' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/18\n",
      "    Target Word : gate\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enter' 'gate' 'making' 'obeisance' 'wish']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/18\n",
      "    Target Word : making\n",
      "    - Windowing...\n",
      "      Windowing Words : ['enter' 'gate' 'making' 'obeisance' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/18\n",
      "    Target Word : obeisance\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forgiveness' 'gate' 'making' 'obeisance' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/18\n",
      "    Target Word : say\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forgive' 'forgiveness' 'making' 'obeisance' 'say']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/18\n",
      "    Target Word : forgiveness\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forgive' 'forgiveness' 'obeisance' 'say' 'wrong']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/18\n",
      "    Target Word : forgive\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forgive' 'forgiveness' 'give' 'say' 'wrong']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/18\n",
      "    Target Word : wrong\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forgive' 'forgiveness' 'give' 'good' 'wrong']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/18\n",
      "    Target Word : give\n",
      "    - Windowing...\n",
      "      Windowing Words : ['forgive' 'give' 'good' 'others' 'wrong']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/18\n",
      "    Target Word : good\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'good' 'others' 'wrong']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/18\n",
      "    Target Word : others\n",
      "    - Windowing...\n",
      "      Windowing Words : ['give' 'good' 'others']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 65/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/9\n",
      "    Target Word : unjust\n",
      "    - Windowing...\n",
      "      Windowing Words : ['changed' 'saying' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/9\n",
      "    Target Word : changed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['changed' 'saying' 'spoken' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/9\n",
      "    Target Word : saying\n",
      "    - Windowing...\n",
      "      Windowing Words : ['changed' 'saying' 'sent' 'spoken' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/9\n",
      "    Target Word : spoken\n",
      "    - Windowing...\n",
      "      Windowing Words : ['changed' 'saying' 'sent' 'spoken' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/9\n",
      "    Target Word : sent\n",
      "    - Windowing...\n",
      "      Windowing Words : ['saying' 'sent' 'spoken' 'unjust' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/9\n",
      "    Target Word : upon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['pestilence' 'sent' 'spoken' 'unjust' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/9\n",
      "    Target Word : unjust\n",
      "    - Windowing...\n",
      "      Windowing Words : ['heaven' 'pestilence' 'sent' 'unjust' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/9\n",
      "    Target Word : pestilence\n",
      "    - Windowing...\n",
      "      Windowing Words : ['heaven' 'pestilence' 'transgressed' 'unjust' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/9\n",
      "    Target Word : heaven\n",
      "    - Windowing...\n",
      "      Windowing Words : ['heaven' 'pestilence' 'transgressed' 'unjust']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/9\n",
      "    Target Word : transgressed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['heaven' 'pestilence' 'transgressed']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 66/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/23\n",
      "    Target Word : musa\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drink' 'musa' 'prayed']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/23\n",
      "    Target Word : prayed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drink' 'musa' 'people' 'prayed']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/23\n",
      "    Target Word : drink\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drink' 'musa' 'people' 'prayed' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/23\n",
      "    Target Word : people\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drink' 'people' 'prayed' 'said' 'strike']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/23\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drink' 'people' 'rock' 'said' 'strike']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/23\n",
      "    Target Word : strike\n",
      "    - Windowing...\n",
      "      Windowing Words : ['people' 'rock' 'said' 'staff' 'strike']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/23\n",
      "    Target Word : rock\n",
      "    - Windowing...\n",
      "      Windowing Words : ['gushed' 'rock' 'said' 'staff' 'strike']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/23\n",
      "    Target Word : staff\n",
      "    - Windowing...\n",
      "      Windowing Words : ['gushed' 'rock' 'staff' 'strike' 'twelve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/23\n",
      "    Target Word : gushed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['gushed' 'rock' 'spring' 'staff' 'twelve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/23\n",
      "    Target Word : twelve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['gushed' 'spring' 'staff' 'tribe' 'twelve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/23\n",
      "    Target Word : spring\n",
      "    - Windowing...\n",
      "      Windowing Words : ['gushed' 'knew' 'spring' 'tribe' 'twelve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/23\n",
      "    Target Word : tribe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drinking' 'knew' 'spring' 'tribe' 'twelve']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 12/23\n",
      "    Target Word : knew\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drinking' 'knew' 'place' 'spring' 'tribe']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/23\n",
      "    Target Word : drinking\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drinking' 'eat' 'knew' 'place' 'tribe']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/23\n",
      "    Target Word : place\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drink' 'drinking' 'eat' 'knew' 'place']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/23\n",
      "    Target Word : eat\n",
      "    - Windowing...\n",
      "      Windowing Words : ['drink' 'drinking' 'eat' 'place' 'provision']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/23\n",
      "    Target Word : drink\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'drink' 'eat' 'place' 'provision']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/23\n",
      "    Target Word : provision\n",
      "    - Windowing...\n",
      "      Windowing Words : ['act' 'allah' 'drink' 'eat' 'provision']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/23\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['act' 'allah' 'corruptly' 'drink' 'provision']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 19/23\n",
      "    Target Word : act\n",
      "    - Windowing...\n",
      "      Windowing Words : ['act' 'allah' 'corruptly' 'land' 'provision']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 20/23\n",
      "    Target Word : corruptly\n",
      "    - Windowing...\n",
      "      Windowing Words : ['act' 'allah' 'corruptly' 'land' 'making']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 21/23\n",
      "    Target Word : land\n",
      "    - Windowing...\n",
      "      Windowing Words : ['act' 'corruptly' 'land' 'making' 'mischief']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 22/23\n",
      "    Target Word : making\n",
      "    - Windowing...\n",
      "      Windowing Words : ['corruptly' 'land' 'making' 'mischief']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 23/23\n",
      "    Target Word : mischief\n",
      "    - Windowing...\n",
      "      Windowing Words : ['land' 'making' 'mischief']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 67/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/43\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cannot' 'musa' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/43\n",
      "    Target Word : musa\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'cannot' 'musa' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/43\n",
      "    Target Word : cannot\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'cannot' 'musa' 'one' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/43\n",
      "    Target Word : bear\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'cannot' 'food' 'musa' 'one']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/43\n",
      "    Target Word : one\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'cannot' 'food' 'one' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/43\n",
      "    Target Word : food\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'food' 'one' 'pray' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/43\n",
      "    Target Word : therefore\n",
      "    - Windowing...\n",
      "      Windowing Words : ['food' 'lord' 'one' 'pray' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/43\n",
      "    Target Word : pray\n",
      "    - Windowing...\n",
      "      Windowing Words : ['behalf' 'food' 'lord' 'pray' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/43\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['behalf' 'bring' 'lord' 'pray' 'therefore']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/43\n",
      "    Target Word : behalf\n",
      "    - Windowing...\n",
      "      Windowing Words : ['behalf' 'bring' 'forth' 'lord' 'pray']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/43\n",
      "    Target Word : bring\n",
      "    - Windowing...\n",
      "      Windowing Words : ['behalf' 'bring' 'forth' 'lord' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/43\n",
      "    Target Word : forth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['behalf' 'bring' 'earth' 'forth' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/43\n",
      "    Target Word : u\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bring' 'earth' 'forth' 'grows' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/43\n",
      "    Target Word : earth\n",
      "    - Windowing...\n",
      "      Windowing Words : ['earth' 'forth' 'grows' 'herb' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/43\n",
      "    Target Word : grows\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cucumber' 'earth' 'grows' 'herb' 'u']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/43\n",
      "    Target Word : herb\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cucumber' 'earth' 'garlic' 'grows' 'herb']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/43\n",
      "    Target Word : cucumber\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cucumber' 'garlic' 'grows' 'herb' 'lentil']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/43\n",
      "    Target Word : garlic\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cucumber' 'garlic' 'herb' 'lentil' 'onion']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 18/43\n",
      "    Target Word : lentil\n",
      "    - Windowing...\n",
      "      Windowing Words : ['cucumber' 'garlic' 'lentil' 'onion' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 19/43\n",
      "    Target Word : onion\n",
      "    - Windowing...\n",
      "      Windowing Words : ['exchange' 'garlic' 'lentil' 'onion' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 20/43\n",
      "    Target Word : said\n",
      "    - Windowing...\n",
      "      Windowing Words : ['better' 'exchange' 'lentil' 'onion' 'said']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 21/43\n",
      "    Target Word : exchange\n",
      "    - Windowing...\n",
      "      Windowing Words : ['better' 'exchange' 'onion' 'said' 'worse']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 22/43\n",
      "    Target Word : better\n",
      "    - Windowing...\n",
      "      Windowing Words : ['better' 'enter' 'exchange' 'said' 'worse']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 23/43\n",
      "    Target Word : worse\n",
      "    - Windowing...\n",
      "      Windowing Words : ['better' 'city' 'enter' 'exchange' 'worse']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 24/43\n",
      "    Target Word : enter\n",
      "    - Windowing...\n",
      "      Windowing Words : ['ask' 'better' 'city' 'enter' 'worse']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 25/43\n",
      "    Target Word : city\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abasement' 'ask' 'city' 'enter' 'worse']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 26/43\n",
      "    Target Word : ask\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abasement' 'ask' 'city' 'enter' 'humiliation']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 27/43\n",
      "    Target Word : abasement\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abasement' 'ask' 'brought' 'city' 'humiliation']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 28/43\n",
      "    Target Word : humiliation\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abasement' 'ask' 'brought' 'humiliation' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 29/43\n",
      "    Target Word : brought\n",
      "    - Windowing...\n",
      "      Windowing Words : ['abasement' 'became' 'brought' 'humiliation' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 30/43\n",
      "    Target Word : upon\n",
      "    - Windowing...\n",
      "      Windowing Words : ['became' 'brought' 'deserving' 'humiliation' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 31/43\n",
      "    Target Word : became\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'became' 'brought' 'deserving' 'upon']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 32/43\n",
      "    Target Word : deserving\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'became' 'deserving' 'upon' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 33/43\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'became' 'deserving' 'disbelieved' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 34/43\n",
      "    Target Word : wrath\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'communication' 'deserving' 'disbelieved' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 35/43\n",
      "    Target Word : disbelieved\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'communication' 'disbelieved' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 36/43\n",
      "    Target Word : communication\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'communication' 'disbelieved' 'killed' 'wrath']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 37/43\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'communication' 'disbelieved' 'killed' 'prophet']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 38/43\n",
      "    Target Word : killed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'communication' 'killed' 'prophet' 'unjustly']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 39/43\n",
      "    Target Word : prophet\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'disobeyed' 'killed' 'prophet' 'unjustly']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 40/43\n",
      "    Target Word : unjustly\n",
      "    - Windowing...\n",
      "      Windowing Words : ['disobeyed' 'exceeded' 'killed' 'prophet' 'unjustly']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 41/43\n",
      "    Target Word : disobeyed\n",
      "    - Windowing...\n",
      "      Windowing Words : ['disobeyed' 'exceeded' 'limit' 'prophet' 'unjustly']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 42/43\n",
      "    Target Word : exceeded\n",
      "    - Windowing...\n",
      "      Windowing Words : ['disobeyed' 'exceeded' 'limit' 'unjustly']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 43/43\n",
      "    Target Word : limit\n",
      "    - Windowing...\n",
      "      Windowing Words : ['disobeyed' 'exceeded' 'limit']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 68/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/17\n",
      "    Target Word : surely\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'jew' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/17\n",
      "    Target Word : believe\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'f' 'jew' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/17\n",
      "    Target Word : jew\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'christian' 'f' 'jew' 'surely']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/17\n",
      "    Target Word : f\n",
      "    - Windowing...\n",
      "      Windowing Words : ['believe' 'christian' 'f' 'jew' 'sabians']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/17\n",
      "    Target Word : christian\n",
      "    - Windowing...\n",
      "      Windowing Words : ['christian' 'f' 'jew' 'sabians' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/17\n",
      "    Target Word : sabians\n",
      "    - Windowing...\n",
      "      Windowing Words : ['belief' 'christian' 'f' 'sabians' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/17\n",
      "    Target Word : whoever\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'belief' 'christian' 'sabians' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/17\n",
      "    Target Word : belief\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'belief' 'last' 'sabians' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/17\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'belief' 'day' 'last' 'whoever']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/17\n",
      "    Target Word : last\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'belief' 'day' 'good' 'last']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/17\n",
      "    Target Word : day\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'day' 'good' 'last' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/17\n",
      "    Target Word : good\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'good' 'last' 'reward' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       - Target Word Vector...\n",
      "  # Terget Word 12/17\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['day' 'good' 'lord' 'reward' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/17\n",
      "    Target Word : reward\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fear' 'good' 'lord' 'reward' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/17\n",
      "    Target Word : lord\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fear' 'lord' 'reward' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 15/17\n",
      "    Target Word : fear\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fear' 'grieve' 'lord' 'reward' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 16/17\n",
      "    Target Word : shall\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fear' 'grieve' 'lord' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 17/17\n",
      "    Target Word : grieve\n",
      "    - Windowing...\n",
      "      Windowing Words : ['fear' 'grieve' 'shall']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 69/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/14\n",
      "    Target Word : took\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lifted' 'promise' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/14\n",
      "    Target Word : promise\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lifted' 'mountain' 'promise' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/14\n",
      "    Target Word : lifted\n",
      "    - Windowing...\n",
      "      Windowing Words : ['lifted' 'mountain' 'promise' 'take' 'took']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/14\n",
      "    Target Word : mountain\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hold' 'lifted' 'mountain' 'promise' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/14\n",
      "    Target Word : take\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hold' 'law' 'lifted' 'mountain' 'take']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/14\n",
      "    Target Word : hold\n",
      "    - Windowing...\n",
      "      Windowing Words : ['hold' 'law' 'mountain' 'take' 'tavrat']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/14\n",
      "    Target Word : law\n",
      "    - Windowing...\n",
      "      Windowing Words : ['given' 'hold' 'law' 'take' 'tavrat']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/14\n",
      "    Target Word : tavrat\n",
      "    - Windowing...\n",
      "      Windowing Words : ['firmness' 'given' 'hold' 'law' 'tavrat']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/14\n",
      "    Target Word : given\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'firmness' 'given' 'law' 'tavrat']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 9/14\n",
      "    Target Word : firmness\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'firmness' 'given' 'mind' 'tavrat']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 10/14\n",
      "    Target Word : bear\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'firmness' 'given' 'may' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 11/14\n",
      "    Target Word : mind\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'firmness' 'guard' 'may' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 12/14\n",
      "    Target Word : may\n",
      "    - Windowing...\n",
      "      Windowing Words : ['bear' 'evil' 'guard' 'may' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 13/14\n",
      "    Target Word : guard\n",
      "    - Windowing...\n",
      "      Windowing Words : ['evil' 'guard' 'may' 'mind']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 14/14\n",
      "    Target Word : evil\n",
      "    - Windowing...\n",
      "      Windowing Words : ['evil' 'guard' 'may']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "==== AYAT - 70/99 ====\n",
      "# Lesk Algorithm...\n",
      "- Creating DataFrame Terms Concept...\n",
      "- Windowing & Weighting...\n",
      "  # Terget Word 0/8\n",
      "    Target Word : turned\n",
      "    - Windowing...\n",
      "      Windowing Words : ['back' 'grace' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 1/8\n",
      "    Target Word : back\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'back' 'grace' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 2/8\n",
      "    Target Word : grace\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'back' 'grace' 'mercy' 'turned']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 3/8\n",
      "    Target Word : allah\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'back' 'grace' 'mercy' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 4/8\n",
      "    Target Word : mercy\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'certainly' 'grace' 'mercy' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 5/8\n",
      "    Target Word : would\n",
      "    - Windowing...\n",
      "      Windowing Words : ['allah' 'among' 'certainly' 'mercy' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 6/8\n",
      "    Target Word : certainly\n",
      "    - Windowing...\n",
      "      Windowing Words : ['among' 'certainly' 'loser' 'mercy' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 7/8\n",
      "    Target Word : among\n",
      "    - Windowing...\n",
      "      Windowing Words : ['among' 'certainly' 'loser' 'would']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n",
      "  # Terget Word 8/8\n",
      "    Target Word : loser\n",
      "    - Windowing...\n",
      "      Windowing Words : ['among' 'certainly' 'loser']\n",
      "    - Weighting...\n",
      "       - Count Overlaps...\n",
      "       - Normalized Concept...\n",
      "       - Target Word Vector...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-53671c09ecbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_window\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mleskAlgorithm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_window\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# listWeightedAyat = leskAlgorithm(n_window)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# saveTermsByConceptMatrices(listWeightedAyat) ### ubah path yang lesk outputnya\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# listWeightedAyat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-b96d70c3fa69>\u001b[0m in \u001b[0;36mleskAlgorithm\u001b[1;34m(n_window)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0msaveTermsByConceptMatrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdictPerAyat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleskOutputPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./assets/leskOutput/ayat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-eb98249167ad>\u001b[0m in \u001b[0;36msaveTermsByConceptMatrices\u001b[1;34m(idx, listWeightedAyat, leskOutputPath)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msaveTermsByConceptMatrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlistWeightedAyat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleskOutputPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./assets/leskOutput/ayat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}_{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleskOutputPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistWeightedAyat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "n_window = 2\n",
    "leskAlgorithm(n_window)\n",
    "# listWeightedAyat = leskAlgorithm(n_window)\n",
    "# saveTermsByConceptMatrices(listWeightedAyat) ### ubah path yang lesk outputnya\n",
    "# listWeightedAyat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7f7b50f4e2c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# if file is not empty scores will be equal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# to the value unpickled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# scores = {} # scores is an empty dict already\n",
    "# target = \"./assets/realTrainLeskModel_1_100.bin.txt\"\n",
    "# if os.path.getsize(target) > 0:      \n",
    "#     with open(target, \"rb\") as f:\n",
    "#         unpickler = pickle.Unpickler(f)\n",
    "#         # if file is not empty scores will be equal\n",
    "#         # to the value unpickled\n",
    "#         scores = unpickler.load()\n",
    "\n",
    "# scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # readFileBin(\"./assets/realTrainLeskModel_1_100.bin.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Classification (Semantic Naive Bayes) - LESK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hitung probability FINAL untuk tiap kelas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbabilityDataTest(probClass, testDataInClass):\n",
    "    # sum all cell\n",
    "    sumAllCell = np.ravel(testDataInClass.values).sum()\n",
    "    # productAllCell = np.prod(testDataInClass.values)\n",
    "\n",
    "    # jumlahkan dengan probability class-nya\n",
    "    classProbForTest = np.log(probClass) + sumAllCell\n",
    "    # classProbForTest = probClass * productAllCell\n",
    "\n",
    "    return classProbForTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping data test dengan fitur di data train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapDataToClass(test_data, superMatrixClass):\n",
    "    # ambil token ayat dari test data\n",
    "    tokenAyat = test_data['token_ayat']\n",
    "\n",
    "    # ambil super matrix dengan index/terms yang ada di tokenAyat\n",
    "    superMatrixTest = superMatrixClass.loc[tokenAyat]\n",
    "\n",
    "    return superMatrixTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hitung Super Matriks dan Probability Tiap Cell-nya untuk Data dengan kelas tertentu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLogCell(cellValue):\n",
    "    if cellValue == 0:\n",
    "        return cellValue\n",
    "    # hasil log(0.__) akan bernilai negatif, itu tidak apa-apa, hasilnya sama saja\n",
    "    return np.log(cellValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 1. ============'''\n",
    "''' \n",
    "### DONE Date: 25/10/2020 ###\n",
    "Input   : dataPerClass\n",
    "Output  : super matrix dari kelas tersebut\n",
    "Problem : -\n",
    "''' \n",
    "def createSuperMatrix(dataPerClass):\n",
    "    # kalo datanya kosong untuk salah satu kelas-nya\n",
    "    if len(dataPerClass) == 0:\n",
    "        return 'empty'\n",
    "\n",
    "    # inisialisasi df kosong untuk dataPerClass\n",
    "    # ini bisa error kalo datanya kosong untuk salah satu kelas-nya, karena ada ini \"dataPerClass[0]\" > makanya cek dulu diatas\n",
    "    dfAccumulatorDataPerClass = pd.DataFrame(0.0, columns=dataPerClass[0][\"weightedAyat\"].columns, index=dataPerClass[0][\"weightedAyat\"].index)\n",
    "    # inisiasi variable untuk total penjumlahan cell keseluruhan pada class tersebut\n",
    "    accumulatorAllCells = 0\n",
    "    \n",
    "    # looping untuk tiap data di class tersebut\n",
    "    for i, data in enumerate(dataPerClass):\n",
    "        print(\"data ke - {} / {}\".format(i, len(dataPerClass)-1))\n",
    "        # jumahkan tiap cells di seluruh doc yang classnya sama rumusnya yang W*(t_i, s_j, c) -> matriks\n",
    "        dfAccumulatorDataPerClass = dfAccumulatorDataPerClass.add(data[\"weightedAyat\"], fill_value=0)\n",
    "    \n",
    "    # jumlahkan keseluruhan cells di seleuruh doc yang classnya sama sigma_t . sigma_s W*(t, s, c) + |V||S| -> float \n",
    "    accumulatorAllCells += (dfAccumulatorDataPerClass.to_numpy().sum() / len(dataPerClass)) + (len(dataPerClass[0]['weightedAyat'].index) * len(dataPerClass[0]['weightedAyat'].columns))\n",
    "\n",
    "    # bagi setiap cell-nya dengan jumlah data train di kelas itu\n",
    "    dfAccumulatorDataPerClass = dfAccumulatorDataPerClass.div(len(dataPerClass))\n",
    "\n",
    "    # bagi lagi tiap cell-nya dengan nilai accumulator | Pr(M_ij|c) + 1 -> rumus probability cell\n",
    "    dfAccumulatorDataPerClass = dfAccumulatorDataPerClass.add(1).div(accumulatorAllCells)\n",
    "\n",
    "    # '''GAK PAKE LOG DULU'''\n",
    "    # log-kan setiap cell-nya | logPr(M_ij|c) -> rumus prob. cell pakai log\n",
    "    dfAccumulatorDataPerClass = dfAccumulatorDataPerClass.applymap(calculateLogCell)\n",
    "    # dari bentuk tuple, rubah lagi ke dataframe, agar supaya gampang ngolahnya\n",
    "    dfAccumulatorDataPerClass = pd.DataFrame(dfAccumulatorDataPerClass)\n",
    "        \n",
    "    return dfAccumulatorDataPerClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fungsi Utama Predict Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkZero(arr):\n",
    "    for i in arr:\n",
    "        if i == 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# checkZero([1,2,4,3, 0])\n",
    "\n",
    "'''============ 6. ============'''\n",
    "''' \n",
    "### DONE Date: 25/10/2020 ###\n",
    "Input   : train data & test data\n",
    "Output  : hasil prediksi data test\n",
    "Problem : -\n",
    "''' \n",
    "def createProbabilityModel(listPredictionLabelTest, currentBinaryLabel, class0_train_data, class1_train_data, test_data, probClass0, probClass1):\n",
    "    predictionLabelTest = list()\n",
    "    # predictionLabelTest['label_number'] = currentBinaryLabel\n",
    "\n",
    "    # |c| jumlah data belonging to the class c\n",
    "    totalDocClass0 = len(class0_train_data)\n",
    "    totalDocClass1 = len(class1_train_data)\n",
    "    \n",
    "    # buat super matrix dan hitung probability tiap cell-nya | sampai ke rumus logPr(M_ij|c)\n",
    "    print(\"== creating super matrix class 0... ==\")\n",
    "    superMatrixClass0 = createSuperMatrix(class0_train_data) \n",
    "    print(\"== creating super matrix class 1... ==\")\n",
    "    superMatrixClass1 = createSuperMatrix(class1_train_data)\n",
    "\n",
    "    # display(superMatrixClass1)\n",
    "    # print(checkZero(np.ravel(superMatrixClass1.values)))\n",
    "\n",
    "    # looping untuk tiap-tiap testing data\n",
    "    for i, dTest in enumerate(test_data):\n",
    "        # mapping fitur data train ke data testing\n",
    "        if type(superMatrixClass0) == str:\n",
    "            # kalau matrix kelas 0 nya ga ada, otomatis di prediksi ke kelas 1\n",
    "            predictionLabelTest.append(1)\n",
    "            # predictionLabelTest[str(i)] = 1\n",
    "            # listPredictionLabelTest.append(predictionLabelTest)\n",
    "            continue # lanjut ke next data test\n",
    "        elif type(superMatrixClass1) == str:\n",
    "            # kalau matrix kelas 1 nya ga ada, otomatis di prediksi ke kelas 0\n",
    "            predictionLabelTest.append(0)\n",
    "            # predictionLabelTest[str(i)] = 0\n",
    "            # listPredictionLabelTest.append(predictionLabelTest)\n",
    "            continue # lanjut ke next data test\n",
    "\n",
    "        testDataInClass0 = mapDataToClass(dTest, superMatrixClass0)\n",
    "        testDataInClass1 = mapDataToClass(dTest, superMatrixClass1)\n",
    "\n",
    "        print(\"Testing Data ke : \", i+1)\n",
    "        display(testDataInClass0)\n",
    "        display(testDataInClass1)\n",
    "\n",
    "        print(\"NILAI PROBABILITY\")\n",
    "        # hitung nilai probability untuk tiap kelasnya\n",
    "        probabilityClass0 = calculateProbabilityDataTest(probClass0, testDataInClass0) \n",
    "        probabilityClass1 = calculateProbabilityDataTest(probClass1, testDataInClass1)\n",
    "\n",
    "        # tampung prob di list\n",
    "        listProb = [probabilityClass0, probabilityClass1]\n",
    "\n",
    "        print(\"Nilai log(Prob) untuk Kelas 0 : \", probabilityClass0)\n",
    "        print(\"Nilai log(Prob) untuk Kelas 1 : \", probabilityClass1)\n",
    "        print(\"Max Value        : \", max(listProb))\n",
    "        \n",
    "        # tentuin classnya berdasarkan nomor indexnya\n",
    "        classPrediction = listProb.index(max(listProb))\n",
    "        predictionLabelTest.append(classPrediction)\n",
    "        # predictionLabelTest[i] = classPrediction\n",
    "        print(\"Label Prediction : \", classPrediction)\n",
    "\n",
    "    listPredictionLabelTest.append(predictionLabelTest)\n",
    "\n",
    "    return listPredictionLabelTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hitung Probilitas Untuk Kelas 0 dan 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 7. ============'''\n",
    "''' \n",
    "### DONE Date: 25/10/2020 ###\n",
    "Input   : class0_train_data, class1_train_data, number_train_data\n",
    "Output  : class prob untuk tiap kelasnya\n",
    "Problem : -\n",
    "''' \n",
    "def calculateClassProbability(number_class0_train_data, number_class1_train_data, number_train_data):\n",
    "    # probability class 0\n",
    "    probClass0 = number_class0_train_data / number_train_data\n",
    "    # probability class 1\n",
    "    probClass1 = number_class1_train_data / number_train_data\n",
    "        \n",
    "    return probClass0, probClass1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pisahkan Data Train dan Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 8. ============'''\n",
    "''' \n",
    "### DONE Date: 25/10/2020 ###\n",
    "Input   : train data\n",
    "Output  : train data yang telah dikelompokkan berdasarkan kelasnya\n",
    "Problem : -\n",
    "''' \n",
    "def devideTrainDataByClass(train_data, currentBinaryLabel):\n",
    "    class0_train_data, class1_train_data = list(), list()\n",
    "    \n",
    "    for i, data in enumerate(train_data):\n",
    "        if data[\"labelsPerAyat\"][currentBinaryLabel] == 0:\n",
    "            class0_train_data.append(data)\n",
    "        else:\n",
    "            class1_train_data.append(data)\n",
    "    \n",
    "    return class0_train_data, class1_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data Train & Test**\n",
    "```\n",
    "# Pembagiannya masih untuk DUMMY\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''============ 9. ============'''\n",
    "''' \n",
    "### DONE Date: 22/10/2020 ###\n",
    "Input   : listWeightedAyat\n",
    "Output  : train data & test data\n",
    "Problem : -\n",
    "''' \n",
    "def splitData(listWeightedAyat):\n",
    "    # Shuffle ayat agar yang dijadikan data test adalah random\n",
    "#    random.shuffle(listWeightedAyat)\n",
    "\n",
    "    # ambil train data\n",
    "    train_data = listWeightedAyat[:14]\n",
    "\n",
    "    # ambil data terjemahannya dulu dari sheet\n",
    "    listAyatInString = pd.read_excel(datapath, sheet_name='proceed-data').Terjemahan.values[13:]\n",
    "    labelsAllAyat = pd.read_excel(datapath, sheet_name='proceed-data').iloc[:,4:20].values[13:]\n",
    "\n",
    "    # list test data\n",
    "    test_data = []\n",
    "    for i, ayat in enumerate(listAyatInString):\n",
    "        test_data.append({\n",
    "          'token_ayat' : ast.literal_eval(listAyatInString[i]),\n",
    "          'label_ayat' : labelsAllAyat[i]\n",
    "        })\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Classification**\n",
    "\n",
    "```\n",
    "# Bagaimana kalau data trainnya hanya punya 1 label, hanya punya kelas 0 atau kelasnya 1 saja?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leskModel = readFileBin(leskOutputPath)\n",
    "leskModel\n",
    "\n",
    "#listWeightedAyat = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "# load data terms-by-concept matriks dari file bin\n",
    "listWeightedAyat = readFileBin(leskOutputPath)\n",
    "# panggill fungsi main / entar pake ini\n",
    "#mainClassification(listWeightedAyat)\n",
    "train_data, test_data = splitData(listWeightedAyat)\n",
    "# nama label untuk dataset\n",
    "labelsName = list(range(16))\n",
    "# inisialisasi dict untuk prediction result\n",
    "listPredictionLabelTest = list()\n",
    "\n",
    "\n",
    "# ALTERNATIF 1\n",
    "for currentBinaryLabel in labelsName:\n",
    "  # kelompokkan data train berdasarkan kelasnya\n",
    "  class0_train_data, class1_train_data = devideTrainDataByClass(train_data, currentBinaryLabel)\n",
    "\n",
    "  # hitung probabilitas per kelasnya\n",
    "  probClass0, probClass1 = calculateClassProbability(len(class0_train_data), len(class1_train_data), len(train_data))\n",
    "\n",
    "  # buat model probability menggunakan SNB untuk currentBinaryLabel\n",
    "  listPredictionLabelTest = createProbabilityModel(listPredictionLabelTest, currentBinaryLabel, class0_train_data, class1_train_data, test_data, probClass0, probClass1)\n",
    "  # listPredictionLabelTest.append(predictionLabelTest)\n",
    "\n",
    "listPredictionLabelTest\n",
    "\n",
    "\n",
    "\n",
    "# # ALTERNATFIF 2\n",
    "# # ambil label ke-2 | diitung dari 0\n",
    "# currentBinaryLabel = 0 \n",
    "# # kelompokkan data train berdasarkan kelasnya\n",
    "# class0_train_data, class1_train_data = devideTrainDataByClass(train_data, currentBinaryLabel)\n",
    "\n",
    "# # hitung probabilitas per kelasnya\n",
    "# probClass0, probClass1 = calculateClassProbability(len(class0_train_data), len(class1_train_data), len(train_data))\n",
    "\n",
    "# # buat model probability menggunakan SNB untuk currentBinaryLabel\n",
    "# listPredictionLabelTest = createProbabilityModel(listPredictionLabelTest, currentBinaryLabel, class0_train_data, class1_train_data, test_data, probClass0, probClass1)\n",
    "# # listPredictionLabelTest.append(predictionLabelTest)\n",
    "\n",
    "# listPredictionLabelTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rapihkan Label Prediksi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# banyak data test\n",
    "listLenTest = list(range(len(test_data)))\n",
    "\n",
    "# simpan di pandas dataframe\n",
    "dfLabelPred = pd.DataFrame(listPredictionLabelTest, columns=listLenTest)\n",
    "\n",
    "# lakukan transpose, biar bentuknya sama dengan data di excel\n",
    "dfLabelPred = dfLabelPred.T\n",
    "\n",
    "dfLabelPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Siapkan Label Aktual dari Data Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actualLabel = []\n",
    "for test in test_data:\n",
    "    actualLabel.append(test['label_ayat'])\n",
    "\n",
    "dfActualLabel = pd.DataFrame(actualLabel)\n",
    "\n",
    "dfActualLabel# **Classification (Semantic Naive Bayes) - LESK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_loss(label_pred, label_real, len_data, jum_label):\n",
    "    count_salah = 0\n",
    "    for i, pred in enumerate(label_pred):\n",
    "        for j, angka in enumerate(pred):\n",
    "            if label_pred[i][j] == label_real[i][j]:\n",
    "                continue\n",
    "            else:\n",
    "                count_salah += 1\n",
    "    hamming_loss = (1/len_data)*(1/jum_label)*count_salah\n",
    "    print(\"Jumlah Salah  : \", count_salah)\n",
    "    return hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming = hamming_loss(dfLabelPred.values.tolist(), dfActualLabel.values.tolist(), len(test_data), 16)\n",
    "print(\"Nilai Hamming : \", hamming)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
